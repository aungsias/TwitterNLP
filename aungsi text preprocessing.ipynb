{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Preprocessing Tweets](#preprocessing-tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aungs_tko91wk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aungs_tko91wk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aungs_tko91wk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\aungs_tko91wk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\aungs_tko91wk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('words');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unprocessed_tweet</th>\n",
       "      <th>product</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   unprocessed_tweet             product  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "\n",
       "            emotion  \n",
       "0  Negative emotion  \n",
       "1  Positive emotion  \n",
       "2  Positive emotion  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/tweets.csv\", encoding='ISO-8859-1')\n",
    "\n",
    "df.columns = [\"unprocessed_tweet\", \"product\", \"emotion\"]\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       .@wesley83 I have a 3G iPhone. After 3 hrs twe...\n",
       "1       @jessedee Know about @fludapp ? Awesome iPad/i...\n",
       "2       @swonderlin Can not wait for #iPad 2 also. The...\n",
       "3       @sxsw I hope this year's festival isn't as cra...\n",
       "4       @sxtxstate great stuff on Fri #SXSW: Marissa M...\n",
       "                              ...                        \n",
       "9088                        Ipad everywhere. #SXSW {link}\n",
       "9089    Wave, buzz... RT @mention We interrupt your re...\n",
       "9090    Google's Zeiger, a physician never reported po...\n",
       "9091    Some Verizon iPhone customers complained their...\n",
       "9092    Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...\n",
       "Name: unprocessed_tweet, Length: 9093, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df[\"unprocessed_tweet\"]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "stop_words = [i.replace(\"'\", '') for i in stop_words]\n",
    "\n",
    "top_words = ['sxsw', 'mention', 'link', 'rt']\n",
    "stop_words = stop_words + top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       wesley i have a g iphone after  hrs tweeting a...\n",
       "1       jessedee know about fludapp  awesome ipadiphon...\n",
       "2       swonderlin can not wait for ipad  also they sh...\n",
       "3       sxsw i hope this years festival isnt as crashy...\n",
       "4       sxtxstate great stuff on fri sxsw marissa maye...\n",
       "                              ...                        \n",
       "9088                            ipad everywhere sxsw link\n",
       "9089    wave buzz rt mention we interrupt your regular...\n",
       "9090    googles zeiger a physician never reported pote...\n",
       "9091    some verizon iphone customers complained their...\n",
       "9092    rt mention google tests checkin offers at sxsw...\n",
       "Name: unprocessed_tweet, Length: 9093, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = \"[^a-zA-Z\\s]\"\n",
    "\n",
    "text = text.str.replace(ex, \"\", regex=True)\n",
    "text = text.str.lower()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [wesley, i, have, a, g, iphone, after, hrs, tw...\n",
       "1       [jessedee, know, about, fludapp, awesome, ipad...\n",
       "2       [swonderlin, can, not, wait, for, ipad, also, ...\n",
       "3       [sxsw, i, hope, this, years, festival, isnt, a...\n",
       "4       [sxtxstate, great, stuff, on, fri, sxsw, maris...\n",
       "                              ...                        \n",
       "9088                       [ipad, everywhere, sxsw, link]\n",
       "9089    [wave, buzz, rt, mention, we, interrupt, your,...\n",
       "9090    [googles, zeiger, a, physician, never, reporte...\n",
       "9091    [some, verizon, iphone, customers, complained,...\n",
       "9092    [rt, mention, google, tests, checkin, offers, ...\n",
       "Name: unprocessed_tweet, Length: 9093, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokenized_text = text.apply(lambda t: word_tokenize(str(t)))\n",
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [wesley, iphone, hrs, tweeting, riseaustin, de...\n",
       "1       [jessedee, know, fludapp, awesome, ipadiphone,...\n",
       "2                    [swonderlin, wait, ipad, also, sale]\n",
       "3       [hope, years, festival, crashy, years, iphone,...\n",
       "4       [sxtxstate, great, stuff, fri, marissa, mayer,...\n",
       "                              ...                        \n",
       "9088                                   [ipad, everywhere]\n",
       "9089    [wave, buzz, interrupt, regularly, scheduled, ...\n",
       "9090    [googles, zeiger, physician, never, reported, ...\n",
       "9091    [verizon, iphone, customers, complained, time,...\n",
       "9092                     [google, tests, checkin, offers]\n",
       "Name: unprocessed_tweet, Length: 9093, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import pos_tag\n",
    "\n",
    "filtered_text = tokenized_text.apply(lambda x: [\n",
    "    word for word in x if word not in stop_words]\n",
    ")\n",
    "\n",
    "filtered_text = filtered_text.apply(lambda x: [\n",
    "    word for word in x if len(word) > 1]\n",
    ")\n",
    "\n",
    "filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [(wesley, NN), (iphone, NN), (hrs, NN), (tweet...\n",
       "1       [(jessedee, NN), (know, VBP), (fludapp, VBZ), ...\n",
       "2       [(swonderlin, NN), (wait, NN), (ipad, NN), (al...\n",
       "3       [(hope, NN), (years, NNS), (festival, JJ), (cr...\n",
       "4       [(sxtxstate, NN), (great, JJ), (stuff, NN), (f...\n",
       "                              ...                        \n",
       "9088                       [(ipad, NN), (everywhere, RB)]\n",
       "9089    [(wave, NN), (buzz, NN), (interrupt, VBP), (re...\n",
       "9090    [(googles, NNS), (zeiger, RBR), (physician, JJ...\n",
       "9091    [(verizon, NN), (iphone, NN), (customers, NNS)...\n",
       "9092    [(google, NN), (tests, NNS), (checkin, VBP), (...\n",
       "Name: unprocessed_tweet, Length: 9093, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_text = filtered_text.apply(lambda x: pos_tag(x))\n",
    "\n",
    "tagged_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       wesley iphone hr tweet riseaustin dead need up...\n",
       "1       jessedee know fludapp awesome ipadiphone app l...\n",
       "2                          swonderlin wait ipad also sale\n",
       "3               hope year festival crashy year iphone app\n",
       "4       sxtxstate great stuff fri marissa mayer google...\n",
       "                              ...                        \n",
       "9088                                      ipad everywhere\n",
       "9089    wave buzz interrupt regularly schedule geek pr...\n",
       "9090    google zeiger physician never report potential...\n",
       "9091    verizon iphone customer complain time fell bac...\n",
       "9092                            google test checkin offer\n",
       "Name: unprocessed_tweet, Length: 9093, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "lemmatized_text = tagged_text.apply(\n",
    "    lambda x: [lemmatizer.lemmatize(word, get_wordnet_pos(pos)) for word, pos in x]\n",
    ")\n",
    "\n",
    "lemmatized_str = lemmatized_text.apply(lambda x: ' '.join(x))\n",
    "\n",
    "lemmatized_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unprocessed_tweet</th>\n",
       "      <th>product</th>\n",
       "      <th>emotion</th>\n",
       "      <th>processed_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>wesley iphone hr tweet riseaustin dead need up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>jessedee know fludapp awesome ipadiphone app l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>swonderlin wait ipad also sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>hope year festival crashy year iphone app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>sxtxstate great stuff fri marissa mayer google...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   unprocessed_tweet             product  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "            emotion                                    processed_tweet  \n",
       "0  Negative emotion  wesley iphone hr tweet riseaustin dead need up...  \n",
       "1  Positive emotion  jessedee know fludapp awesome ipadiphone app l...  \n",
       "2  Positive emotion                     swonderlin wait ipad also sale  \n",
       "3  Negative emotion          hope year festival crashy year iphone app  \n",
       "4  Positive emotion  sxtxstate great stuff fri marissa mayer google...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"processed_tweet\"] = lemmatized_str\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unprocessed_tweet       1\n",
       "product              5802\n",
       "emotion                 0\n",
       "processed_tweet         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/processed_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binary = df.copy()\n",
    "df_binary = df_binary[df_binary[\"emotion\"].isin([\"Negative emotion\", \"Positive emotion\"])]\n",
    "\n",
    "df_binary[\"emotion_encoded\"] = df_binary[\"emotion\"].replace(\"Negative emotion\", 0).replace(\"Positive emotion\", 1)\n",
    "df_binary.to_csv(\"data/processed_tweets_binary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['processed_tweet'][df['processed_tweet'].str.contains('html')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
