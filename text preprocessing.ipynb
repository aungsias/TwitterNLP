{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Preprocessing Tweets](#preprocessing-tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aungs_tko91wk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aungs_tko91wk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aungs_tko91wk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('punkt');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unprocessed_tweet</th>\n",
       "      <th>product</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   unprocessed_tweet             product  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "\n",
       "            emotion  \n",
       "0  Negative emotion  \n",
       "1  Positive emotion  \n",
       "2  Positive emotion  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/tweets.csv\", encoding='ISO-8859-1')\n",
    "\n",
    "df.columns = [\"unprocessed_tweet\", \"product\", \"emotion\"]\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       .@wesley83 I have a 3G iPhone. After 3 hrs twe...\n",
       "1       @jessedee Know about @fludapp ? Awesome iPad/i...\n",
       "2       @swonderlin Can not wait for #iPad 2 also. The...\n",
       "3       @sxsw I hope this year's festival isn't as cra...\n",
       "4       @sxtxstate great stuff on Fri #SXSW: Marissa M...\n",
       "                              ...                        \n",
       "9088                        Ipad everywhere. #SXSW {link}\n",
       "9089    Wave, buzz... RT @mention We interrupt your re...\n",
       "9090    Google's Zeiger, a physician never reported po...\n",
       "9091    Some Verizon iPhone customers complained their...\n",
       "9092    Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...\n",
       "Name: unprocessed_tweet, Length: 9093, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df[\"unprocessed_tweet\"]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['werent', 'won', 'wont', 'wouldn', 'wouldnt']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "stop_words = [i.replace(\"'\", '') for i in stop_words]\n",
    "\n",
    "stop_words[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       wesley83 i have a 3g iphone after 3 hrs tweeti...\n",
       "1       jessedee know about fludapp  awesome ipadiphon...\n",
       "2       swonderlin can not wait for ipad 2 also they s...\n",
       "3       sxsw i hope this years festival isnt as crashy...\n",
       "4       sxtxstate great stuff on fri sxsw marissa maye...\n",
       "                              ...                        \n",
       "9088                            ipad everywhere sxsw link\n",
       "9089    wave buzz rt mention we interrupt your regular...\n",
       "9090    googles zeiger a physician never reported pote...\n",
       "9091    some verizon iphone customers complained their...\n",
       "9092    rt mention google tests checkin offers at sxsw...\n",
       "Name: unprocessed_tweet, Length: 9093, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = \"[^a-zA-Z0-9\\s]\"\n",
    "\n",
    "text = text.str.replace(ex, \"\", regex=True)\n",
    "text = text.str.lower()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [wesley83, i, have, a, 3g, iphone, after, 3, h...\n",
       "1       [jessedee, know, about, fludapp, awesome, ipad...\n",
       "2       [swonderlin, can, not, wait, for, ipad, 2, als...\n",
       "3       [sxsw, i, hope, this, years, festival, isnt, a...\n",
       "4       [sxtxstate, great, stuff, on, fri, sxsw, maris...\n",
       "                              ...                        \n",
       "9088                       [ipad, everywhere, sxsw, link]\n",
       "9089    [wave, buzz, rt, mention, we, interrupt, your,...\n",
       "9090    [googles, zeiger, a, physician, never, reporte...\n",
       "9091    [some, verizon, iphone, customers, complained,...\n",
       "9092    [rt, mention, google, tests, checkin, offers, ...\n",
       "Name: unprocessed_tweet, Length: 9093, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokenized_text = text.apply(lambda t: word_tokenize(str(t)))\n",
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [wesley83, 3g, iphone, 3, hrs, tweeting, risea...\n",
       "1       [jessedee, know, fludapp, awesome, ipadiphone,...\n",
       "2           [swonderlin, wait, ipad, 2, also, sale, sxsw]\n",
       "3       [sxsw, hope, years, festival, crashy, years, i...\n",
       "4       [sxtxstate, great, stuff, fri, sxsw, marissa, ...\n",
       "                              ...                        \n",
       "9088                       [ipad, everywhere, sxsw, link]\n",
       "9089    [wave, buzz, rt, mention, interrupt, regularly...\n",
       "9090    [googles, zeiger, physician, never, reported, ...\n",
       "9091    [verizon, iphone, customers, complained, time,...\n",
       "9092    [rt, mention, google, tests, checkin, offers, ...\n",
       "Name: unprocessed_tweet, Length: 9093, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_text = tokenized_text.apply(lambda x: [word for word in x if word not in stop_words])\n",
    "filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       wesley83 3g iphone 3 hr tweeting riseaustin de...\n",
       "1       jessedee know fludapp awesome ipadiphone app l...\n",
       "2                   swonderlin wait ipad 2 also sale sxsw\n",
       "3       sxsw hope year festival crashy year iphone app...\n",
       "4       sxtxstate great stuff fri sxsw marissa mayer g...\n",
       "                              ...                        \n",
       "9088                            ipad everywhere sxsw link\n",
       "9089    wave buzz rt mention interrupt regularly sched...\n",
       "9090    google zeiger physician never reported potenti...\n",
       "9091    verizon iphone customer complained time fell b...\n",
       "9092       rt mention google test checkin offer sxsw link\n",
       "Name: unprocessed_tweet, Length: 9093, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_text = filtered_text.apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "lemmatized_str = lemmatized_text.apply(lambda x: ' '.join(x))\n",
    "lemmatized_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unprocessed_tweet</th>\n",
       "      <th>product</th>\n",
       "      <th>emotion</th>\n",
       "      <th>processed_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>wesley83 3g iphone 3 hr tweeting riseaustin de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>jessedee know fludapp awesome ipadiphone app l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>swonderlin wait ipad 2 also sale sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>sxsw hope year festival crashy year iphone app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>sxtxstate great stuff fri sxsw marissa mayer g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   unprocessed_tweet             product  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "            emotion                                    processed_tweet  \n",
       "0  Negative emotion  wesley83 3g iphone 3 hr tweeting riseaustin de...  \n",
       "1  Positive emotion  jessedee know fludapp awesome ipadiphone app l...  \n",
       "2  Positive emotion              swonderlin wait ipad 2 also sale sxsw  \n",
       "3  Negative emotion  sxsw hope year festival crashy year iphone app...  \n",
       "4  Positive emotion  sxtxstate great stuff fri sxsw marissa mayer g...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"processed_tweet\"] = lemmatized_str\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/processed_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binary = df.copy()\n",
    "df_binary = df_binary[df_binary[\"emotion\"].isin([\"Negative emotion\", \"Positive emotion\"])]\n",
    "\n",
    "df_binary[\"emotion_encoded\"] = df_binary[\"emotion\"].replace(\"Negative emotion\", 0).replace(\"Positive emotion\", 1)\n",
    "df_binary.to_csv(\"data/processed_tweets_binary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
