{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Preprocessing Tweets](#preprocessing-tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/michaelromanski/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/michaelromanski/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/michaelromanski/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, silhouette_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('punkt');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unprocessed_tweet</th>\n",
       "      <th>product</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   unprocessed_tweet             product  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "\n",
       "            emotion  \n",
       "0  Negative emotion  \n",
       "1  Positive emotion  \n",
       "2  Positive emotion  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/tweets.csv\", encoding='ISO-8859-1')\n",
    "\n",
    "df.columns = [\"unprocessed_tweet\", \"product\", \"emotion\"]\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       .@wesley83 I have a 3G iPhone. After 3 hrs twe...\n",
       "1       @jessedee Know about @fludapp ? Awesome iPad/i...\n",
       "2       @swonderlin Can not wait for #iPad 2 also. The...\n",
       "3       @sxsw I hope this year's festival isn't as cra...\n",
       "4       @sxtxstate great stuff on Fri #SXSW: Marissa M...\n",
       "                              ...                        \n",
       "9088                        Ipad everywhere. #SXSW {link}\n",
       "9089    Wave, buzz... RT @mention We interrupt your re...\n",
       "9090    Google's Zeiger, a physician never reported po...\n",
       "9091    Some Verizon iPhone customers complained their...\n",
       "9092    Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...\n",
       "Name: unprocessed_tweet, Length: 9093, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df[\"unprocessed_tweet\"]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "stop_words = [i.replace(\"'\", '') for i in stop_words]\n",
    "\n",
    "stop_words[-5:]\n",
    "top_words = ['sxsw', 'mention', 'link', 'rt']\n",
    "stop_words = stop_words + top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       wesley i have a g iphone after  hrs tweeting a...\n",
       "1       jessedee know about fludapp  awesome ipadiphon...\n",
       "2       swonderlin can not wait for ipad  also they sh...\n",
       "3       sxsw i hope this years festival isnt as crashy...\n",
       "4       sxtxstate great stuff on fri sxsw marissa maye...\n",
       "                              ...                        \n",
       "9088                            ipad everywhere sxsw link\n",
       "9089    wave buzz rt mention we interrupt your regular...\n",
       "9090    googles zeiger a physician never reported pote...\n",
       "9091    some verizon iphone customers complained their...\n",
       "9092    rt mention google tests checkin offers at sxsw...\n",
       "Name: unprocessed_tweet, Length: 9093, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = \"[^a-zA-Z\\s]\"\n",
    "\n",
    "text = text.str.replace(ex, \"\", regex=True)\n",
    "text = text.str.lower()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [wesley, i, have, a, g, iphone, after, hrs, tw...\n",
       "1       [jessedee, know, about, fludapp, awesome, ipad...\n",
       "2       [swonderlin, can, not, wait, for, ipad, also, ...\n",
       "3       [sxsw, i, hope, this, years, festival, isnt, a...\n",
       "4       [sxtxstate, great, stuff, on, fri, sxsw, maris...\n",
       "                              ...                        \n",
       "9088                       [ipad, everywhere, sxsw, link]\n",
       "9089    [wave, buzz, rt, mention, we, interrupt, your,...\n",
       "9090    [googles, zeiger, a, physician, never, reporte...\n",
       "9091    [some, verizon, iphone, customers, complained,...\n",
       "9092    [rt, mention, google, tests, checkin, offers, ...\n",
       "Name: unprocessed_tweet, Length: 9093, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokenized_text = text.apply(lambda t: word_tokenize(str(t)))\n",
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [wesley, iphone, hrs, tweeting, riseaustin, de...\n",
       "1       [jessedee, know, fludapp, awesome, ipadiphone,...\n",
       "2                    [swonderlin, wait, ipad, also, sale]\n",
       "3       [hope, years, festival, crashy, years, iphone,...\n",
       "4       [sxtxstate, great, stuff, fri, marissa, mayer,...\n",
       "                              ...                        \n",
       "9088                                   [ipad, everywhere]\n",
       "9089    [wave, buzz, interrupt, regularly, scheduled, ...\n",
       "9090    [googles, zeiger, physician, never, reported, ...\n",
       "9091    [verizon, iphone, customers, complained, time,...\n",
       "9092                     [google, tests, checkin, offers]\n",
       "Name: unprocessed_tweet, Length: 9093, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_text = tokenized_text.apply(lambda x: [word for word in x if word not in stop_words])\n",
    "filtered_text = filtered_text.apply(lambda x: [word for word in x if len(word) > 1])\n",
    "filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [(wesley, NN), (iphone, NN), (hrs, NN), (tweet...\n",
       "1       [(jessedee, NN), (know, VBP), (fludapp, VBZ), ...\n",
       "2       [(swonderlin, NN), (wait, NN), (ipad, NN), (al...\n",
       "3       [(hope, NN), (years, NNS), (festival, JJ), (cr...\n",
       "4       [(sxtxstate, NN), (great, JJ), (stuff, NN), (f...\n",
       "                              ...                        \n",
       "9088                       [(ipad, NN), (everywhere, RB)]\n",
       "9089    [(wave, NN), (buzz, NN), (interrupt, VBP), (re...\n",
       "9090    [(googles, NNS), (zeiger, RBR), (physician, JJ...\n",
       "9091    [(verizon, NN), (iphone, NN), (customers, NNS)...\n",
       "9092    [(google, NN), (tests, NNS), (checkin, VBP), (...\n",
       "Name: unprocessed_tweet, Length: 9093, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_text = filtered_text.apply(lambda x: pos_tag(x))\n",
    "tagged_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       wesley iphone hr tweet riseaustin dead need up...\n",
       "1       jessedee know fludapp awesome ipadiphone app l...\n",
       "2                          swonderlin wait ipad also sale\n",
       "3               hope year festival crashy year iphone app\n",
       "4       sxtxstate great stuff fri marissa mayer google...\n",
       "                              ...                        \n",
       "9088                                      ipad everywhere\n",
       "9089    wave buzz interrupt regularly schedule geek pr...\n",
       "9090    google zeiger physician never report potential...\n",
       "9091    verizon iphone customer complain time fell bac...\n",
       "9092                            google test checkin offer\n",
       "Name: unprocessed_tweet, Length: 9093, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "lemmatized_text = tagged_text.apply(\n",
    "    lambda x: [lemmatizer.lemmatize(word, get_wordnet_pos(pos)) for word, pos in x]\n",
    ")\n",
    "\n",
    "lemmatized_str = lemmatized_text.apply(lambda x: ' '.join(x))\n",
    "\n",
    "lemmatized_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [wesley, iphone, hr, tweet, riseaustin, dead, ...\n",
       "1       [jessedee, know, fludapp, awesome, ipadiphone,...\n",
       "2                    [swonderlin, wait, ipad, also, sale]\n",
       "3       [hope, year, festival, crashy, year, iphone, app]\n",
       "4       [sxtxstate, great, stuff, fri, marissa, mayer,...\n",
       "                              ...                        \n",
       "9088                                   [ipad, everywhere]\n",
       "9089    [wave, buzz, interrupt, regularly, schedule, g...\n",
       "9090    [google, zeiger, physician, never, report, pot...\n",
       "9091    [verizon, iphone, customer, complain, time, fe...\n",
       "9092                       [google, test, checkin, offer]\n",
       "Name: unprocessed_tweet, Length: 9093, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unprocessed_tweet</th>\n",
       "      <th>product</th>\n",
       "      <th>emotion</th>\n",
       "      <th>processed_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>wesley iphone hr tweet riseaustin dead need up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>jessedee know fludapp awesome ipadiphone app l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>swonderlin wait ipad also sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>hope year festival crashy year iphone app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>sxtxstate great stuff fri marissa mayer google...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   unprocessed_tweet             product  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "            emotion                                    processed_tweet  \n",
       "0  Negative emotion  wesley iphone hr tweet riseaustin dead need up...  \n",
       "1  Positive emotion  jessedee know fludapp awesome ipadiphone app l...  \n",
       "2  Positive emotion                     swonderlin wait ipad also sale  \n",
       "3  Negative emotion          hope year festival crashy year iphone app  \n",
       "4  Positive emotion  sxtxstate great stuff fri marissa mayer google...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"processed_tweet\"] = lemmatized_str\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/processed_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binary = df.copy()\n",
    "df_binary = df_binary[df_binary[\"emotion\"].isin([\"Negative emotion\", \"Positive emotion\"])]\n",
    "\n",
    "df_binary[\"emotion_encoded\"] = df_binary[\"emotion\"].replace(\"Negative emotion\", 0).replace(\"Positive emotion\", 1)\n",
    "df_binary.to_csv(\"data/processed_tweets_binary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unprocessed_tweet</th>\n",
       "      <th>product</th>\n",
       "      <th>emotion</th>\n",
       "      <th>processed_tweet</th>\n",
       "      <th>emotion_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>wesley iphone hr tweet riseaustin dead need up...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>jessedee know fludapp awesome ipadiphone app l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>swonderlin wait ipad also sale</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>hope year festival crashy year iphone app</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>sxtxstate great stuff fri marissa mayer google...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9077</th>\n",
       "      <td>@mention your PR guy just convinced me to swit...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>pr guy convince switch back iphone great cover...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9079</th>\n",
       "      <td>&amp;quot;papyrus...sort of like the ipad&amp;quot; - ...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>quotpapyrussort like ipadquot nice lol lavelle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9080</th>\n",
       "      <td>Diller says Google TV &amp;quot;might be run over ...</td>\n",
       "      <td>Other Google product or service</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>diller say google tv quotmight run playstation...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9085</th>\n",
       "      <td>I've always used Camera+ for my iPhone b/c it ...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>ive always use camera iphone bc image stabiliz...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>ipad everywhere</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3548 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      unprocessed_tweet  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3     @sxsw I hope this year's festival isn't as cra...   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "...                                                 ...   \n",
       "9077  @mention your PR guy just convinced me to swit...   \n",
       "9079  &quot;papyrus...sort of like the ipad&quot; - ...   \n",
       "9080  Diller says Google TV &quot;might be run over ...   \n",
       "9085  I've always used Camera+ for my iPhone b/c it ...   \n",
       "9088                      Ipad everywhere. #SXSW {link}   \n",
       "\n",
       "                              product           emotion  \\\n",
       "0                              iPhone  Negative emotion   \n",
       "1                  iPad or iPhone App  Positive emotion   \n",
       "2                                iPad  Positive emotion   \n",
       "3                  iPad or iPhone App  Negative emotion   \n",
       "4                              Google  Positive emotion   \n",
       "...                               ...               ...   \n",
       "9077                           iPhone  Positive emotion   \n",
       "9079                             iPad  Positive emotion   \n",
       "9080  Other Google product or service  Negative emotion   \n",
       "9085               iPad or iPhone App  Positive emotion   \n",
       "9088                             iPad  Positive emotion   \n",
       "\n",
       "                                        processed_tweet  emotion_encoded  \n",
       "0     wesley iphone hr tweet riseaustin dead need up...                0  \n",
       "1     jessedee know fludapp awesome ipadiphone app l...                1  \n",
       "2                        swonderlin wait ipad also sale                1  \n",
       "3             hope year festival crashy year iphone app                0  \n",
       "4     sxtxstate great stuff fri marissa mayer google...                1  \n",
       "...                                                 ...              ...  \n",
       "9077  pr guy convince switch back iphone great cover...                1  \n",
       "9079     quotpapyrussort like ipadquot nice lol lavelle                1  \n",
       "9080  diller say google tv quotmight run playstation...                0  \n",
       "9085  ive always use camera iphone bc image stabiliz...                1  \n",
       "9088                                    ipad everywhere                1  \n",
       "\n",
       "[3548 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2978\n",
       "0     570\n",
       "Name: emotion_encoded, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_binary['emotion_encoded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_binary['processed_tweet']\n",
    "y = df_binary['emotion_encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_forest_pipe = Pipeline([\n",
    "    ('tf', TfidfVectorizer(min_df=.01, max_df=.9, stop_words=stop_words)),\n",
    "    ('rf', RandomForestClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8577464788732394"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_forest_pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred_forest = bin_forest_pipe.predict(X_test)\n",
    "forest_test_acc = accuracy_score(y_test, y_pred_forest)\n",
    "forest_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fefa0710d90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfm_forest = confusion_matrix(y_test, y_pred_forest)\n",
    "ConfusionMatrixDisplay(cfm_forest).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85211268, 0.84859155, 0.8556338 , 0.86419753, 0.85361552])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_score = cross_val_score(bin_forest_pipe, X_train, y_train, cv=5)\n",
    "forest_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_forest_pipe_grid = Pipeline([\n",
    "    ('tf', TfidfVectorizer(stop_words=stop_words)),\n",
    "    ('rf', RandomForestClassifier(random_state=42))\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_param_grid = {\n",
    "    'tf__min_df': [.01, .02, .03],\n",
    "    'tf__max_df': [.88, .90, .92],\n",
    "    'tf__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'rf__n_estimators': [86, 88, 90],\n",
    "    'rf__min_samples_split': [10, 20, 30],\n",
    "    'rf__class_weight': [None, 'balanced', 'balanced_subsample']\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;tf&#x27;,\n",
       "                                        TfidfVectorizer(stop_words=[&#x27;i&#x27;, &#x27;me&#x27;,\n",
       "                                                                    &#x27;my&#x27;,\n",
       "                                                                    &#x27;myself&#x27;,\n",
       "                                                                    &#x27;we&#x27;, &#x27;our&#x27;,\n",
       "                                                                    &#x27;ours&#x27;,\n",
       "                                                                    &#x27;ourselves&#x27;,\n",
       "                                                                    &#x27;you&#x27;,\n",
       "                                                                    &#x27;youre&#x27;,\n",
       "                                                                    &#x27;youve&#x27;,\n",
       "                                                                    &#x27;youll&#x27;,\n",
       "                                                                    &#x27;youd&#x27;,\n",
       "                                                                    &#x27;your&#x27;,\n",
       "                                                                    &#x27;yours&#x27;,\n",
       "                                                                    &#x27;yourself&#x27;,\n",
       "                                                                    &#x27;yourselves&#x27;,\n",
       "                                                                    &#x27;he&#x27;, &#x27;him&#x27;,\n",
       "                                                                    &#x27;his&#x27;,\n",
       "                                                                    &#x27;himself&#x27;,\n",
       "                                                                    &#x27;she&#x27;,\n",
       "                                                                    &#x27;shes&#x27;,\n",
       "                                                                    &#x27;her&#x27;,\n",
       "                                                                    &#x27;hers&#x27;,\n",
       "                                                                    &#x27;herself&#x27;,\n",
       "                                                                    &#x27;it&#x27;, &#x27;its&#x27;,\n",
       "                                                                    &#x27;its&#x27;,\n",
       "                                                                    &#x27;itself&#x27;, ...])),\n",
       "                                       (&#x27;rf&#x27;,\n",
       "                                        RandomForestClassifier(random_state=42))]),\n",
       "             n_jobs=-2,\n",
       "             param_grid={&#x27;rf__class_weight&#x27;: [None, &#x27;balanced&#x27;,\n",
       "                                              &#x27;balanced_subsample&#x27;],\n",
       "                         &#x27;rf__min_samples_split&#x27;: [10, 20, 30],\n",
       "                         &#x27;rf__n_estimators&#x27;: [86, 88, 90],\n",
       "                         &#x27;tf__max_df&#x27;: [0.88, 0.9, 0.92],\n",
       "                         &#x27;tf__min_df&#x27;: [0.01, 0.02, 0.03],\n",
       "                         &#x27;tf__ngram_range&#x27;: [(1, 1), (1, 2), (1, 3)]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;tf&#x27;,\n",
       "                                        TfidfVectorizer(stop_words=[&#x27;i&#x27;, &#x27;me&#x27;,\n",
       "                                                                    &#x27;my&#x27;,\n",
       "                                                                    &#x27;myself&#x27;,\n",
       "                                                                    &#x27;we&#x27;, &#x27;our&#x27;,\n",
       "                                                                    &#x27;ours&#x27;,\n",
       "                                                                    &#x27;ourselves&#x27;,\n",
       "                                                                    &#x27;you&#x27;,\n",
       "                                                                    &#x27;youre&#x27;,\n",
       "                                                                    &#x27;youve&#x27;,\n",
       "                                                                    &#x27;youll&#x27;,\n",
       "                                                                    &#x27;youd&#x27;,\n",
       "                                                                    &#x27;your&#x27;,\n",
       "                                                                    &#x27;yours&#x27;,\n",
       "                                                                    &#x27;yourself&#x27;,\n",
       "                                                                    &#x27;yourselves&#x27;,\n",
       "                                                                    &#x27;he&#x27;, &#x27;him&#x27;,\n",
       "                                                                    &#x27;his&#x27;,\n",
       "                                                                    &#x27;himself&#x27;,\n",
       "                                                                    &#x27;she&#x27;,\n",
       "                                                                    &#x27;shes&#x27;,\n",
       "                                                                    &#x27;her&#x27;,\n",
       "                                                                    &#x27;hers&#x27;,\n",
       "                                                                    &#x27;herself&#x27;,\n",
       "                                                                    &#x27;it&#x27;, &#x27;its&#x27;,\n",
       "                                                                    &#x27;its&#x27;,\n",
       "                                                                    &#x27;itself&#x27;, ...])),\n",
       "                                       (&#x27;rf&#x27;,\n",
       "                                        RandomForestClassifier(random_state=42))]),\n",
       "             n_jobs=-2,\n",
       "             param_grid={&#x27;rf__class_weight&#x27;: [None, &#x27;balanced&#x27;,\n",
       "                                              &#x27;balanced_subsample&#x27;],\n",
       "                         &#x27;rf__min_samples_split&#x27;: [10, 20, 30],\n",
       "                         &#x27;rf__n_estimators&#x27;: [86, 88, 90],\n",
       "                         &#x27;tf__max_df&#x27;: [0.88, 0.9, 0.92],\n",
       "                         &#x27;tf__min_df&#x27;: [0.01, 0.02, 0.03],\n",
       "                         &#x27;tf__ngram_range&#x27;: [(1, 1), (1, 2), (1, 3)]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tf&#x27;,\n",
       "                 TfidfVectorizer(stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;,\n",
       "                                             &#x27;our&#x27;, &#x27;ours&#x27;, &#x27;ourselves&#x27;, &#x27;you&#x27;,\n",
       "                                             &#x27;youre&#x27;, &#x27;youve&#x27;, &#x27;youll&#x27;, &#x27;youd&#x27;,\n",
       "                                             &#x27;your&#x27;, &#x27;yours&#x27;, &#x27;yourself&#x27;,\n",
       "                                             &#x27;yourselves&#x27;, &#x27;he&#x27;, &#x27;him&#x27;, &#x27;his&#x27;,\n",
       "                                             &#x27;himself&#x27;, &#x27;she&#x27;, &#x27;shes&#x27;, &#x27;her&#x27;,\n",
       "                                             &#x27;hers&#x27;, &#x27;herself&#x27;, &#x27;it&#x27;, &#x27;its&#x27;,\n",
       "                                             &#x27;its&#x27;, &#x27;itself&#x27;, ...])),\n",
       "                (&#x27;rf&#x27;, RandomForestClassifier(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                            &#x27;ourselves&#x27;, &#x27;you&#x27;, &#x27;youre&#x27;, &#x27;youve&#x27;, &#x27;youll&#x27;,\n",
       "                            &#x27;youd&#x27;, &#x27;your&#x27;, &#x27;yours&#x27;, &#x27;yourself&#x27;, &#x27;yourselves&#x27;,\n",
       "                            &#x27;he&#x27;, &#x27;him&#x27;, &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;, &#x27;shes&#x27;, &#x27;her&#x27;,\n",
       "                            &#x27;hers&#x27;, &#x27;herself&#x27;, &#x27;it&#x27;, &#x27;its&#x27;, &#x27;its&#x27;, &#x27;itself&#x27;, ...])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tf',\n",
       "                                        TfidfVectorizer(stop_words=['i', 'me',\n",
       "                                                                    'my',\n",
       "                                                                    'myself',\n",
       "                                                                    'we', 'our',\n",
       "                                                                    'ours',\n",
       "                                                                    'ourselves',\n",
       "                                                                    'you',\n",
       "                                                                    'youre',\n",
       "                                                                    'youve',\n",
       "                                                                    'youll',\n",
       "                                                                    'youd',\n",
       "                                                                    'your',\n",
       "                                                                    'yours',\n",
       "                                                                    'yourself',\n",
       "                                                                    'yourselves',\n",
       "                                                                    'he', 'him',\n",
       "                                                                    'his',\n",
       "                                                                    'himself',\n",
       "                                                                    'she',\n",
       "                                                                    'shes',\n",
       "                                                                    'her',\n",
       "                                                                    'hers',\n",
       "                                                                    'herself',\n",
       "                                                                    'it', 'its',\n",
       "                                                                    'its',\n",
       "                                                                    'itself', ...])),\n",
       "                                       ('rf',\n",
       "                                        RandomForestClassifier(random_state=42))]),\n",
       "             n_jobs=-2,\n",
       "             param_grid={'rf__class_weight': [None, 'balanced',\n",
       "                                              'balanced_subsample'],\n",
       "                         'rf__min_samples_split': [10, 20, 30],\n",
       "                         'rf__n_estimators': [86, 88, 90],\n",
       "                         'tf__max_df': [0.88, 0.9, 0.92],\n",
       "                         'tf__min_df': [0.01, 0.02, 0.03],\n",
       "                         'tf__ngram_range': [(1, 1), (1, 2), (1, 3)]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_forest_grid = GridSearchCV(bin_forest_pipe_grid, forest_param_grid, cv=5, n_jobs=-2, verbose=1, scoring='accuracy')\n",
    "bin_forest_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('tf',\n",
      "                 TfidfVectorizer(max_df=0.88, min_df=0.01,\n",
      "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
      "                                             'our', 'ours', 'ourselves', 'you',\n",
      "                                             'youre', 'youve', 'youll', 'youd',\n",
      "                                             'your', 'yours', 'yourself',\n",
      "                                             'yourselves', 'he', 'him', 'his',\n",
      "                                             'himself', 'she', 'shes', 'her',\n",
      "                                             'hers', 'herself', 'it', 'its',\n",
      "                                             'its', 'itself', ...])),\n",
      "                ('rf',\n",
      "                 RandomForestClassifier(min_samples_split=10, n_estimators=86,\n",
      "                                        random_state=42))])\n",
      "{'rf__class_weight': None, 'rf__min_samples_split': 10, 'rf__n_estimators': 86, 'tf__max_df': 0.88, 'tf__min_df': 0.01, 'tf__ngram_range': (1, 1)}\n",
      "0.8520133144546289\n"
     ]
    }
   ],
   "source": [
    "print(bin_forest_grid.best_estimator_)\n",
    "print(bin_forest_grid.best_params_)\n",
    "print(bin_forest_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fef8110ee50>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_forest_grid = bin_forest_grid.predict(X_test)\n",
    "cfm_forest = confusion_matrix(y_test, y_pred_forest_grid)\n",
    "ConfusionMatrixDisplay(cfm_forest).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.84859155, 0.84507042, 0.85387324, 0.85890653, 0.84479718])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_score = cross_val_score(bin_forest_grid, X_train, y_train, cv=5)\n",
    "forest_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_log_pipe = Pipeline([\n",
    "    ('tf', TfidfVectorizer(min_df=.01, max_df=.9, stop_words=stop_words)),\n",
    "    ('lr', LogisticRegression(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8352112676056338"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_log_pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred_log = bin_log_pipe.predict(X_test)\n",
    "log_test_acc = accuracy_score(y_test, y_pred_log)\n",
    "log_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fef71f1e040>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfm_log = confusion_matrix(y_test, y_pred_log)\n",
    "ConfusionMatrixDisplay(cfm_log).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83978873, 0.84683099, 0.83978873, 0.84479718, 0.84303351])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_score = cross_val_score(bin_log_pipe, X_train, y_train, cv=5)\n",
    "log_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_log_pipe_grid = Pipeline([\n",
    "    ('tf', TfidfVectorizer(stop_words=stop_words)),\n",
    "    ('lr', LogisticRegression(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_param_grid = {\n",
    "    'tf__min_df': [.01, .02, .03],\n",
    "    'tf__max_df': [.88, .90, .92],\n",
    "    'tf__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "    'lr__penalty': [None, 'l2', 'l1'],\n",
    "    'lr__class_weight': [None, 'balanced'],\n",
    "    'lr__solver': ['lbfgs', 'liblinear'],\n",
    "    'lr__max_iter': [10, 15, 20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "1620 fits failed out of a total of 4860.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "810 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1227, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 1221, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 1060, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "810 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.83721651 0.83263656 0.83087538 0.8336842  0.83227575 0.83192364\n",
      " 0.83897148 0.83897148 0.83897148 0.83721651 0.83263656 0.83087538\n",
      " 0.8336842  0.83227575 0.83192364 0.83897148 0.83897148 0.83897148\n",
      " 0.83721651 0.83263656 0.83087538 0.8336842  0.83227575 0.83192364\n",
      " 0.83897148 0.83897148 0.83897148        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.84073267 0.84038118 0.84038118 0.84002658 0.83967447 0.83967447\n",
      " 0.83967571 0.83967571 0.83967571 0.84073267 0.84038118 0.84038118\n",
      " 0.84002658 0.83967447 0.83967447 0.83967571 0.83967571 0.83967571\n",
      " 0.84073267 0.84038118 0.84038118 0.84002658 0.83967447 0.83967447\n",
      " 0.83967571 0.83967571 0.83967571 0.84319994 0.84249509 0.84178963\n",
      " 0.83967447 0.8400272  0.8400272  0.83967571 0.83967571 0.83967571\n",
      " 0.84319994 0.84249509 0.84178963 0.83967447 0.8400272  0.8400272\n",
      " 0.83967571 0.83967571 0.83967571 0.84319994 0.84249509 0.84178963\n",
      " 0.83967447 0.8400272  0.8400272  0.83967571 0.83967571 0.83967571\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.84425566 0.84249323 0.84249323\n",
      " 0.83932235 0.83932235 0.83932235 0.83967571 0.83967571 0.83967571\n",
      " 0.84425566 0.84249323 0.84249323 0.83932235 0.83932235 0.83932235\n",
      " 0.83967571 0.83967571 0.83967571 0.84425566 0.84249323 0.84249323\n",
      " 0.83932235 0.83932235 0.83932235 0.83967571 0.83967571 0.83967571\n",
      " 0.83404501 0.83369476 0.8326347  0.83297936 0.83227389 0.83227327\n",
      " 0.83826539 0.83861751 0.83861751 0.83404501 0.83369476 0.8326347\n",
      " 0.83297936 0.83227389 0.83227327 0.83826539 0.83861751 0.83861751\n",
      " 0.83404501 0.83369476 0.8326347  0.83297936 0.83227389 0.83227327\n",
      " 0.83826539 0.83861751 0.83861751        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.84284845 0.84320056 0.84355267 0.83967447 0.83967447 0.83967447\n",
      " 0.83967571 0.83967571 0.83967571 0.84284845 0.84320056 0.84355267\n",
      " 0.83967447 0.83967447 0.83967447 0.83967571 0.83967571 0.83967571\n",
      " 0.84284845 0.84320056 0.84355267 0.83967447 0.83967447 0.83967447\n",
      " 0.83967571 0.83967571 0.83967571 0.84319994 0.84249509 0.84178963\n",
      " 0.83967447 0.8400272  0.8400272  0.83967571 0.83967571 0.83967571\n",
      " 0.84319994 0.84249509 0.84178963 0.83967447 0.8400272  0.8400272\n",
      " 0.83967571 0.83967571 0.83967571 0.84319994 0.84249509 0.84178963\n",
      " 0.83967447 0.8400272  0.8400272  0.83967571 0.83967571 0.83967571\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.84425566 0.84249323 0.84249323\n",
      " 0.83932235 0.83932235 0.83932235 0.83967571 0.83967571 0.83967571\n",
      " 0.84425566 0.84249323 0.84249323 0.83932235 0.83932235 0.83932235\n",
      " 0.83967571 0.83967571 0.83967571 0.84425566 0.84249323 0.84249323\n",
      " 0.83932235 0.83932235 0.83932235 0.83967571 0.83967571 0.83967571\n",
      " 0.82910984 0.82735052 0.83193233 0.83720844 0.83685446 0.83685384\n",
      " 0.83967509 0.83932297 0.83932297 0.82910984 0.82735052 0.83193233\n",
      " 0.83720844 0.83685446 0.83685384 0.83967509 0.83932297 0.83932297\n",
      " 0.82910984 0.82735052 0.83193233 0.83720844 0.83685446 0.83685384\n",
      " 0.83967509 0.83932297 0.83932297        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.84319994 0.84214174 0.84214174 0.8400272  0.8400272  0.84073143\n",
      " 0.83967571 0.83967571 0.83967571 0.84319994 0.84214174 0.84214174\n",
      " 0.8400272  0.8400272  0.84073143 0.83967571 0.83967571 0.83967571\n",
      " 0.84319994 0.84214174 0.84214174 0.8400272  0.8400272  0.84073143\n",
      " 0.83967571 0.83967571 0.83967571 0.84319994 0.84249509 0.84178963\n",
      " 0.83967447 0.8400272  0.8400272  0.83967571 0.83967571 0.83967571\n",
      " 0.84319994 0.84249509 0.84178963 0.83967447 0.8400272  0.8400272\n",
      " 0.83967571 0.83967571 0.83967571 0.84319994 0.84249509 0.84178963\n",
      " 0.83967447 0.8400272  0.8400272  0.83967571 0.83967571 0.83967571\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.84425566 0.84249323 0.84249323\n",
      " 0.83932235 0.83932235 0.83932235 0.83967571 0.83967571 0.83967571\n",
      " 0.84425566 0.84249323 0.84249323 0.83932235 0.83932235 0.83932235\n",
      " 0.83967571 0.83967571 0.83967571 0.84425566 0.84249323 0.84249323\n",
      " 0.83932235 0.83932235 0.83932235 0.83967571 0.83967571 0.83967571\n",
      " 0.68745622 0.68851194 0.68780398 0.64869898 0.65292061 0.65432906\n",
      " 0.59019549 0.58455859 0.58455859 0.68745622 0.68851194 0.68780398\n",
      " 0.64869898 0.65292061 0.65432906 0.59019549 0.58455859 0.58455859\n",
      " 0.68745622 0.68851194 0.68780398 0.64869898 0.65292061 0.65432906\n",
      " 0.59019549 0.58455859 0.58455859        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.69380046 0.69767245 0.69732096 0.65397881 0.65327459 0.65362856\n",
      " 0.60324043 0.60006583 0.60006583 0.69380046 0.69767245 0.69732096\n",
      " 0.65397881 0.65327459 0.65362856 0.60324043 0.60006583 0.60006583\n",
      " 0.69380046 0.69767245 0.69732096 0.65397881 0.65327459 0.65362856\n",
      " 0.60324043 0.60006583 0.60006583 0.69661612 0.69802519 0.6976737\n",
      " 0.64904923 0.65221887 0.65327645 0.60218409 0.59830651 0.59830651\n",
      " 0.69661612 0.69802519 0.6976737  0.64904923 0.65221887 0.65327645\n",
      " 0.60218409 0.59830651 0.59830651 0.69661612 0.69802519 0.6976737\n",
      " 0.64904923 0.65221887 0.65327645 0.60218409 0.59830651 0.59830651\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.68076235 0.6821708  0.67970291\n",
      " 0.64199953 0.64305152 0.64305152 0.59337444 0.58421455 0.58421455\n",
      " 0.68076235 0.6821708  0.67970291 0.64199953 0.64305152 0.64305152\n",
      " 0.59337444 0.58421455 0.58421455 0.68076235 0.6821708  0.67970291\n",
      " 0.64199953 0.64305152 0.64305152 0.59337444 0.58421455 0.58421455\n",
      " 0.68921554 0.69133443 0.69274163 0.64693159 0.64763954 0.64728557\n",
      " 0.5983003  0.58878891 0.58878891 0.68921554 0.69133443 0.69274163\n",
      " 0.64693159 0.64763954 0.64728557 0.5983003  0.58878891 0.58878891\n",
      " 0.68921554 0.69133443 0.69274163 0.64693159 0.64763954 0.64728557\n",
      " 0.5983003  0.58878891 0.58878891        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.69415009 0.69767245 0.69837792 0.64834377 0.65116191 0.65186676\n",
      " 0.60077564 0.59689681 0.59689681 0.69415009 0.69767245 0.69837792\n",
      " 0.64834377 0.65116191 0.65186676 0.60077564 0.59689681 0.59689681\n",
      " 0.69415009 0.69767245 0.69837792 0.64834377 0.65116191 0.65186676\n",
      " 0.60077564 0.59689681 0.59689681 0.69661612 0.69802519 0.6976737\n",
      " 0.64904923 0.65221887 0.65327645 0.60218409 0.59830651 0.59830651\n",
      " 0.69661612 0.69802519 0.6976737  0.64904923 0.65221887 0.65327645\n",
      " 0.60218409 0.59830651 0.59830651 0.69661612 0.69802519 0.6976737\n",
      " 0.64904923 0.65221887 0.65327645 0.60218409 0.59830651 0.59830651\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.68040962 0.6821708  0.6793508\n",
      " 0.64235164 0.64340363 0.64269941 0.59337444 0.58351032 0.58351032\n",
      " 0.68040962 0.6821708  0.6793508  0.64235164 0.64340363 0.64269941\n",
      " 0.59337444 0.58351032 0.58351032 0.68040962 0.6821708  0.6793508\n",
      " 0.64235164 0.64340363 0.64269941 0.59337444 0.58351032 0.58351032\n",
      " 0.68393199 0.68005626 0.6821708  0.64834128 0.65327521 0.6543303\n",
      " 0.60112279 0.59019922 0.59019922 0.68393199 0.68005626 0.6821708\n",
      " 0.64834128 0.65327521 0.6543303  0.60112279 0.59019922 0.59019922\n",
      " 0.68393199 0.68005626 0.6821708  0.64834128 0.65327521 0.6543303\n",
      " 0.60112279 0.59019922 0.59019922        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.69626338 0.69802519 0.69837792 0.64975346 0.65257036 0.65292372\n",
      " 0.60147987 0.59725017 0.59725017 0.69626338 0.69802519 0.69837792\n",
      " 0.64975346 0.65257036 0.65292372 0.60147987 0.59725017 0.59725017\n",
      " 0.69626338 0.69802519 0.69837792 0.64975346 0.65257036 0.65292372\n",
      " 0.60147987 0.59725017 0.59725017 0.69661612 0.69802519 0.6976737\n",
      " 0.64904923 0.65221887 0.65327645 0.60218409 0.59830651 0.59830651\n",
      " 0.69661612 0.69802519 0.6976737  0.64904923 0.65221887 0.65327645\n",
      " 0.60218409 0.59830651 0.59830651 0.69661612 0.69802519 0.6976737\n",
      " 0.64904923 0.65221887 0.65327645 0.60218409 0.59830651 0.59830651\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.68040962 0.6821708  0.6793508\n",
      " 0.64235164 0.64340363 0.64269941 0.59337444 0.58351032 0.58351032\n",
      " 0.68040962 0.6821708  0.6793508  0.64235164 0.64340363 0.64269941\n",
      " 0.59337444 0.58351032 0.58351032 0.68040962 0.6821708  0.6793508\n",
      " 0.64235164 0.64340363 0.64269941 0.59337444 0.58351032 0.58351032]\n",
      "  warnings.warn(\n",
      "/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;tf&#x27;,\n",
       "                                        TfidfVectorizer(stop_words=[&#x27;i&#x27;, &#x27;me&#x27;,\n",
       "                                                                    &#x27;my&#x27;,\n",
       "                                                                    &#x27;myself&#x27;,\n",
       "                                                                    &#x27;we&#x27;, &#x27;our&#x27;,\n",
       "                                                                    &#x27;ours&#x27;,\n",
       "                                                                    &#x27;ourselves&#x27;,\n",
       "                                                                    &#x27;you&#x27;,\n",
       "                                                                    &#x27;youre&#x27;,\n",
       "                                                                    &#x27;youve&#x27;,\n",
       "                                                                    &#x27;youll&#x27;,\n",
       "                                                                    &#x27;youd&#x27;,\n",
       "                                                                    &#x27;your&#x27;,\n",
       "                                                                    &#x27;yours&#x27;,\n",
       "                                                                    &#x27;yourself&#x27;,\n",
       "                                                                    &#x27;yourselves&#x27;,\n",
       "                                                                    &#x27;he&#x27;, &#x27;him&#x27;,\n",
       "                                                                    &#x27;his&#x27;,\n",
       "                                                                    &#x27;himself&#x27;,\n",
       "                                                                    &#x27;she&#x27;,\n",
       "                                                                    &#x27;shes&#x27;,\n",
       "                                                                    &#x27;her&#x27;,\n",
       "                                                                    &#x27;hers&#x27;,\n",
       "                                                                    &#x27;herself&#x27;,\n",
       "                                                                    &#x27;it&#x27;, &#x27;its&#x27;,\n",
       "                                                                    &#x27;its&#x27;,\n",
       "                                                                    &#x27;itself&#x27;, ...])),\n",
       "                                       (&#x27;lr&#x27;,\n",
       "                                        LogisticRegression(random_state=42,\n",
       "                                                           verbose=1))]),\n",
       "             n_jobs=-2,\n",
       "             param_grid={&#x27;lr__class_weight&#x27;: [None, &#x27;balanced&#x27;],\n",
       "                         &#x27;lr__max_iter&#x27;: [10, 15, 20],\n",
       "                         &#x27;lr__penalty&#x27;: [None, &#x27;l2&#x27;, &#x27;l1&#x27;],\n",
       "                         &#x27;lr__solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;liblinear&#x27;],\n",
       "                         &#x27;tf__max_df&#x27;: [0.88, 0.9, 0.92],\n",
       "                         &#x27;tf__min_df&#x27;: [0.01, 0.02, 0.03],\n",
       "                         &#x27;tf__ngram_range&#x27;: [(1, 1), (1, 2), (1, 3)]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;tf&#x27;,\n",
       "                                        TfidfVectorizer(stop_words=[&#x27;i&#x27;, &#x27;me&#x27;,\n",
       "                                                                    &#x27;my&#x27;,\n",
       "                                                                    &#x27;myself&#x27;,\n",
       "                                                                    &#x27;we&#x27;, &#x27;our&#x27;,\n",
       "                                                                    &#x27;ours&#x27;,\n",
       "                                                                    &#x27;ourselves&#x27;,\n",
       "                                                                    &#x27;you&#x27;,\n",
       "                                                                    &#x27;youre&#x27;,\n",
       "                                                                    &#x27;youve&#x27;,\n",
       "                                                                    &#x27;youll&#x27;,\n",
       "                                                                    &#x27;youd&#x27;,\n",
       "                                                                    &#x27;your&#x27;,\n",
       "                                                                    &#x27;yours&#x27;,\n",
       "                                                                    &#x27;yourself&#x27;,\n",
       "                                                                    &#x27;yourselves&#x27;,\n",
       "                                                                    &#x27;he&#x27;, &#x27;him&#x27;,\n",
       "                                                                    &#x27;his&#x27;,\n",
       "                                                                    &#x27;himself&#x27;,\n",
       "                                                                    &#x27;she&#x27;,\n",
       "                                                                    &#x27;shes&#x27;,\n",
       "                                                                    &#x27;her&#x27;,\n",
       "                                                                    &#x27;hers&#x27;,\n",
       "                                                                    &#x27;herself&#x27;,\n",
       "                                                                    &#x27;it&#x27;, &#x27;its&#x27;,\n",
       "                                                                    &#x27;its&#x27;,\n",
       "                                                                    &#x27;itself&#x27;, ...])),\n",
       "                                       (&#x27;lr&#x27;,\n",
       "                                        LogisticRegression(random_state=42,\n",
       "                                                           verbose=1))]),\n",
       "             n_jobs=-2,\n",
       "             param_grid={&#x27;lr__class_weight&#x27;: [None, &#x27;balanced&#x27;],\n",
       "                         &#x27;lr__max_iter&#x27;: [10, 15, 20],\n",
       "                         &#x27;lr__penalty&#x27;: [None, &#x27;l2&#x27;, &#x27;l1&#x27;],\n",
       "                         &#x27;lr__solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;liblinear&#x27;],\n",
       "                         &#x27;tf__max_df&#x27;: [0.88, 0.9, 0.92],\n",
       "                         &#x27;tf__min_df&#x27;: [0.01, 0.02, 0.03],\n",
       "                         &#x27;tf__ngram_range&#x27;: [(1, 1), (1, 2), (1, 3)]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tf&#x27;,\n",
       "                 TfidfVectorizer(stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;,\n",
       "                                             &#x27;our&#x27;, &#x27;ours&#x27;, &#x27;ourselves&#x27;, &#x27;you&#x27;,\n",
       "                                             &#x27;youre&#x27;, &#x27;youve&#x27;, &#x27;youll&#x27;, &#x27;youd&#x27;,\n",
       "                                             &#x27;your&#x27;, &#x27;yours&#x27;, &#x27;yourself&#x27;,\n",
       "                                             &#x27;yourselves&#x27;, &#x27;he&#x27;, &#x27;him&#x27;, &#x27;his&#x27;,\n",
       "                                             &#x27;himself&#x27;, &#x27;she&#x27;, &#x27;shes&#x27;, &#x27;her&#x27;,\n",
       "                                             &#x27;hers&#x27;, &#x27;herself&#x27;, &#x27;it&#x27;, &#x27;its&#x27;,\n",
       "                                             &#x27;its&#x27;, &#x27;itself&#x27;, ...])),\n",
       "                (&#x27;lr&#x27;, LogisticRegression(random_state=42, verbose=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                            &#x27;ourselves&#x27;, &#x27;you&#x27;, &#x27;youre&#x27;, &#x27;youve&#x27;, &#x27;youll&#x27;,\n",
       "                            &#x27;youd&#x27;, &#x27;your&#x27;, &#x27;yours&#x27;, &#x27;yourself&#x27;, &#x27;yourselves&#x27;,\n",
       "                            &#x27;he&#x27;, &#x27;him&#x27;, &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;, &#x27;shes&#x27;, &#x27;her&#x27;,\n",
       "                            &#x27;hers&#x27;, &#x27;herself&#x27;, &#x27;it&#x27;, &#x27;its&#x27;, &#x27;its&#x27;, &#x27;itself&#x27;, ...])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42, verbose=1)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tf',\n",
       "                                        TfidfVectorizer(stop_words=['i', 'me',\n",
       "                                                                    'my',\n",
       "                                                                    'myself',\n",
       "                                                                    'we', 'our',\n",
       "                                                                    'ours',\n",
       "                                                                    'ourselves',\n",
       "                                                                    'you',\n",
       "                                                                    'youre',\n",
       "                                                                    'youve',\n",
       "                                                                    'youll',\n",
       "                                                                    'youd',\n",
       "                                                                    'your',\n",
       "                                                                    'yours',\n",
       "                                                                    'yourself',\n",
       "                                                                    'yourselves',\n",
       "                                                                    'he', 'him',\n",
       "                                                                    'his',\n",
       "                                                                    'himself',\n",
       "                                                                    'she',\n",
       "                                                                    'shes',\n",
       "                                                                    'her',\n",
       "                                                                    'hers',\n",
       "                                                                    'herself',\n",
       "                                                                    'it', 'its',\n",
       "                                                                    'its',\n",
       "                                                                    'itself', ...])),\n",
       "                                       ('lr',\n",
       "                                        LogisticRegression(random_state=42,\n",
       "                                                           verbose=1))]),\n",
       "             n_jobs=-2,\n",
       "             param_grid={'lr__class_weight': [None, 'balanced'],\n",
       "                         'lr__max_iter': [10, 15, 20],\n",
       "                         'lr__penalty': [None, 'l2', 'l1'],\n",
       "                         'lr__solver': ['lbfgs', 'liblinear'],\n",
       "                         'tf__max_df': [0.88, 0.9, 0.92],\n",
       "                         'tf__min_df': [0.01, 0.02, 0.03],\n",
       "                         'tf__ngram_range': [(1, 1), (1, 2), (1, 3)]})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_log_grid = GridSearchCV(bin_log_pipe_grid, log_param_grid, cv=5, n_jobs=-2, verbose=1, scoring='accuracy')\n",
    "bin_log_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__class_weight': None, 'lr__max_iter': 10, 'lr__penalty': 'l1', 'lr__solver': 'liblinear', 'tf__max_df': 0.88, 'tf__min_df': 0.01, 'tf__ngram_range': (1, 1)}\n",
      "0.8442556574011973\n"
     ]
    }
   ],
   "source": [
    "print(bin_log_grid.best_params_)\n",
    "print(bin_log_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8408450704225352"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_pred_log_grid = bin_log_grid.predict(X_test)\n",
    "log_test_acc = accuracy_score(y_test, y_pred_log_grid)\n",
    "log_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fef71ffa3a0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfm_log = confusion_matrix(y_test, y_pred_log_grid)\n",
    "ConfusionMatrixDisplay(cfm_log).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "1620 fits failed out of a total of 4860.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "810 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1227, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 1221, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 1060, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "810 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.830837   0.82819383 0.82907489 0.83568282 0.83568282 0.83612335\n",
      " 0.84052863 0.84096916 0.84096916 0.830837   0.82819383 0.82907489\n",
      " 0.83568282 0.83568282 0.83612335 0.84052863 0.84096916 0.84096916\n",
      " 0.830837   0.82819383 0.82907489 0.83568282 0.83568282 0.83612335\n",
      " 0.84052863 0.84096916 0.84096916        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.84185022 0.84229075 0.84096916 0.83920705 0.83964758 0.83964758\n",
      " 0.83964758 0.83964758 0.83964758 0.84185022 0.84229075 0.84096916\n",
      " 0.83920705 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758\n",
      " 0.84185022 0.84229075 0.84096916 0.83920705 0.83964758 0.83964758\n",
      " 0.83964758 0.83964758 0.83964758 0.84052863 0.84140969 0.84140969\n",
      " 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758\n",
      " 0.84052863 0.84140969 0.84140969 0.83964758 0.83964758 0.83964758\n",
      " 0.83964758 0.83964758 0.83964758 0.84052863 0.84140969 0.84140969\n",
      " 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.83964758 0.83920705 0.83876652\n",
      " 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758\n",
      " 0.83964758 0.83920705 0.83876652 0.83964758 0.83964758 0.83964758\n",
      " 0.83964758 0.83964758 0.83964758 0.83964758 0.83920705 0.83876652\n",
      " 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758\n",
      " 0.83524229 0.83127753 0.83171806 0.83436123 0.83480176 0.83480176\n",
      " 0.83920705 0.83876652 0.83876652 0.83524229 0.83127753 0.83171806\n",
      " 0.83436123 0.83480176 0.83480176 0.83920705 0.83876652 0.83876652\n",
      " 0.83524229 0.83127753 0.83171806 0.83436123 0.83480176 0.83480176\n",
      " 0.83920705 0.83876652 0.83876652        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.84052863 0.84096916 0.84140969 0.83964758 0.84008811 0.84008811\n",
      " 0.83964758 0.83964758 0.83964758 0.84052863 0.84096916 0.84140969\n",
      " 0.83964758 0.84008811 0.84008811 0.83964758 0.83964758 0.83964758\n",
      " 0.84052863 0.84096916 0.84140969 0.83964758 0.84008811 0.84008811\n",
      " 0.83964758 0.83964758 0.83964758 0.84052863 0.84140969 0.84140969\n",
      " 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758\n",
      " 0.84052863 0.84140969 0.84140969 0.83964758 0.83964758 0.83964758\n",
      " 0.83964758 0.83964758 0.83964758 0.84052863 0.84140969 0.84140969\n",
      " 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.83964758 0.83920705 0.83920705\n",
      " 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758\n",
      " 0.83964758 0.83920705 0.83920705 0.83964758 0.83964758 0.83964758\n",
      " 0.83964758 0.83964758 0.83964758 0.83964758 0.83920705 0.83920705\n",
      " 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758\n",
      " 0.83303965 0.830837   0.82819383 0.83656388 0.83480176 0.83524229\n",
      " 0.84008811 0.83964758 0.83964758 0.83303965 0.830837   0.82819383\n",
      " 0.83656388 0.83480176 0.83524229 0.84008811 0.83964758 0.83964758\n",
      " 0.83303965 0.830837   0.82819383 0.83656388 0.83480176 0.83524229\n",
      " 0.84008811 0.83964758 0.83964758        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.84052863 0.84185022 0.84229075 0.84008811 0.83964758 0.84008811\n",
      " 0.83964758 0.83964758 0.83964758 0.84052863 0.84185022 0.84229075\n",
      " 0.84008811 0.83964758 0.84008811 0.83964758 0.83964758 0.83964758\n",
      " 0.84052863 0.84185022 0.84229075 0.84008811 0.83964758 0.84008811\n",
      " 0.83964758 0.83964758 0.83964758 0.84052863 0.84140969 0.84140969\n",
      " 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758\n",
      " 0.84052863 0.84140969 0.84140969 0.83964758 0.83964758 0.83964758\n",
      " 0.83964758 0.83964758 0.83964758 0.84052863 0.84140969 0.84140969\n",
      " 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.83964758 0.83920705 0.83920705\n",
      " 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758\n",
      " 0.83964758 0.83920705 0.83920705 0.83964758 0.83964758 0.83964758\n",
      " 0.83964758 0.83964758 0.83964758 0.83964758 0.83920705 0.83920705\n",
      " 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758\n",
      " 0.68590308 0.68502203 0.68502203 0.64625551 0.64229075 0.63832599\n",
      " 0.59779736 0.59515419 0.59515419 0.68590308 0.68502203 0.68502203\n",
      " 0.64625551 0.64229075 0.63832599 0.59779736 0.59515419 0.59515419\n",
      " 0.68590308 0.68502203 0.68502203 0.64625551 0.64229075 0.63832599\n",
      " 0.59779736 0.59515419 0.59515419        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.69295154 0.69823789 0.69779736 0.64845815 0.65242291 0.65770925\n",
      " 0.60484581 0.60484581 0.60484581 0.69295154 0.69823789 0.69779736\n",
      " 0.64845815 0.65242291 0.65770925 0.60484581 0.60484581 0.60484581\n",
      " 0.69295154 0.69823789 0.69779736 0.64845815 0.65242291 0.65770925\n",
      " 0.60484581 0.60484581 0.60484581 0.69471366 0.69647577 0.7\n",
      " 0.65066079 0.65418502 0.65638767 0.59867841 0.60044053 0.60044053\n",
      " 0.69471366 0.69647577 0.7        0.65066079 0.65418502 0.65638767\n",
      " 0.59867841 0.60044053 0.60044053 0.69471366 0.69647577 0.7\n",
      " 0.65066079 0.65418502 0.65638767 0.59867841 0.60044053 0.60044053\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.68105727 0.68325991 0.68810573\n",
      " 0.63259912 0.64096916 0.64008811 0.59030837 0.58061674 0.58061674\n",
      " 0.68105727 0.68325991 0.68810573 0.63259912 0.64096916 0.64008811\n",
      " 0.59030837 0.58061674 0.58061674 0.68105727 0.68325991 0.68810573\n",
      " 0.63259912 0.64096916 0.64008811 0.59030837 0.58061674 0.58061674\n",
      " 0.67621145 0.68105727 0.68237885 0.64052863 0.64185022 0.63920705\n",
      " 0.59955947 0.59207048 0.59207048 0.67621145 0.68105727 0.68237885\n",
      " 0.64052863 0.64185022 0.63920705 0.59955947 0.59207048 0.59207048\n",
      " 0.67621145 0.68105727 0.68237885 0.64052863 0.64185022 0.63920705\n",
      " 0.59955947 0.59207048 0.59207048        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.69339207 0.69603524 0.70044053 0.65198238 0.65418502 0.65594714\n",
      " 0.6        0.6        0.6        0.69339207 0.69603524 0.70044053\n",
      " 0.65198238 0.65418502 0.65594714 0.6        0.6        0.6\n",
      " 0.69339207 0.69603524 0.70044053 0.65198238 0.65418502 0.65594714\n",
      " 0.6        0.6        0.6        0.69471366 0.69647577 0.7\n",
      " 0.65066079 0.65418502 0.65638767 0.59867841 0.60044053 0.60044053\n",
      " 0.69471366 0.69647577 0.7        0.65066079 0.65418502 0.65638767\n",
      " 0.59867841 0.60044053 0.60044053 0.69471366 0.69647577 0.7\n",
      " 0.65066079 0.65418502 0.65638767 0.59867841 0.60044053 0.60044053\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.68105727 0.68325991 0.68810573\n",
      " 0.63259912 0.64052863 0.64008811 0.59251101 0.5814978  0.5814978\n",
      " 0.68105727 0.68325991 0.68810573 0.63259912 0.64052863 0.64008811\n",
      " 0.59251101 0.5814978  0.5814978  0.68105727 0.68325991 0.68810573\n",
      " 0.63259912 0.64052863 0.64008811 0.59251101 0.5814978  0.5814978\n",
      " 0.67488987 0.67621145 0.67973568 0.63788546 0.63876652 0.63612335\n",
      " 0.60264317 0.58898678 0.58898678 0.67488987 0.67621145 0.67973568\n",
      " 0.63788546 0.63876652 0.63612335 0.60264317 0.58898678 0.58898678\n",
      " 0.67488987 0.67621145 0.67973568 0.63788546 0.63876652 0.63612335\n",
      " 0.60264317 0.58898678 0.58898678        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.6938326  0.69647577 0.7        0.65066079 0.65374449 0.65638767\n",
      " 0.59779736 0.60044053 0.60044053 0.6938326  0.69647577 0.7\n",
      " 0.65066079 0.65374449 0.65638767 0.59779736 0.60044053 0.60044053\n",
      " 0.6938326  0.69647577 0.7        0.65066079 0.65374449 0.65638767\n",
      " 0.59779736 0.60044053 0.60044053 0.69471366 0.69647577 0.7\n",
      " 0.65066079 0.65418502 0.65638767 0.59867841 0.60044053 0.60044053\n",
      " 0.69471366 0.69647577 0.7        0.65066079 0.65418502 0.65638767\n",
      " 0.59867841 0.60044053 0.60044053 0.69471366 0.69647577 0.7\n",
      " 0.65066079 0.65418502 0.65638767 0.59867841 0.60044053 0.60044053\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.68105727 0.68325991 0.68810573\n",
      " 0.63259912 0.64052863 0.64008811 0.59251101 0.5814978  0.5814978\n",
      " 0.68105727 0.68325991 0.68810573 0.63259912 0.64052863 0.64008811\n",
      " 0.59251101 0.5814978  0.5814978  0.68105727 0.68325991 0.68810573\n",
      " 0.63259912 0.64052863 0.64008811 0.59251101 0.5814978  0.5814978 ]\n",
      "  warnings.warn(\n",
      "/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "1620 fits failed out of a total of 4860.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "810 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1227, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 1221, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 1060, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "810 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.83303965 0.83348018 0.83215859 0.83480176 0.83348018 0.83303965\n",
      " 0.83612335 0.83612335 0.83612335 0.83303965 0.83348018 0.83215859\n",
      " 0.83480176 0.83348018 0.83303965 0.83612335 0.83612335 0.83612335\n",
      " 0.83303965 0.83348018 0.83215859 0.83480176 0.83348018 0.83303965\n",
      " 0.83612335 0.83612335 0.83612335        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.83832599 0.83788546 0.83788546 0.83832599 0.83788546 0.83788546\n",
      " 0.83920705 0.83920705 0.83920705 0.83832599 0.83788546 0.83788546\n",
      " 0.83832599 0.83788546 0.83788546 0.83920705 0.83920705 0.83920705\n",
      " 0.83832599 0.83788546 0.83788546 0.83832599 0.83788546 0.83788546\n",
      " 0.83920705 0.83920705 0.83920705 0.83832599 0.83744493 0.83744493\n",
      " 0.83876652 0.83876652 0.83876652 0.83920705 0.83920705 0.83920705\n",
      " 0.83832599 0.83744493 0.83744493 0.83876652 0.83876652 0.83876652\n",
      " 0.83920705 0.83920705 0.83920705 0.83832599 0.83744493 0.83744493\n",
      " 0.83876652 0.83876652 0.83876652 0.83920705 0.83920705 0.83920705\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.83568282 0.83436123 0.83436123\n",
      " 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758\n",
      " 0.83568282 0.83436123 0.83436123 0.83964758 0.83964758 0.83964758\n",
      " 0.83964758 0.83964758 0.83964758 0.83568282 0.83436123 0.83436123\n",
      " 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758\n",
      " 0.82951542 0.830837   0.83171806 0.83127753 0.83215859 0.83215859\n",
      " 0.83744493 0.83744493 0.83744493 0.82951542 0.830837   0.83171806\n",
      " 0.83127753 0.83215859 0.83215859 0.83744493 0.83744493 0.83744493\n",
      " 0.82951542 0.830837   0.83171806 0.83127753 0.83215859 0.83215859\n",
      " 0.83744493 0.83744493 0.83744493        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.83788546 0.83788546 0.83832599 0.83876652 0.83876652 0.83876652\n",
      " 0.83920705 0.83920705 0.83920705 0.83788546 0.83788546 0.83832599\n",
      " 0.83876652 0.83876652 0.83876652 0.83920705 0.83920705 0.83920705\n",
      " 0.83788546 0.83788546 0.83832599 0.83876652 0.83876652 0.83876652\n",
      " 0.83920705 0.83920705 0.83920705 0.83832599 0.83744493 0.83744493\n",
      " 0.83876652 0.83876652 0.83876652 0.83920705 0.83920705 0.83920705\n",
      " 0.83832599 0.83744493 0.83744493 0.83876652 0.83876652 0.83876652\n",
      " 0.83920705 0.83920705 0.83920705 0.83832599 0.83744493 0.83744493\n",
      " 0.83876652 0.83876652 0.83876652 0.83920705 0.83920705 0.83920705\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.83568282 0.83436123 0.83436123\n",
      " 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758\n",
      " 0.83568282 0.83436123 0.83436123 0.83964758 0.83964758 0.83964758\n",
      " 0.83964758 0.83964758 0.83964758 0.83568282 0.83436123 0.83436123\n",
      " 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758\n",
      " 0.82863436 0.83039648 0.82995595 0.83436123 0.83039648 0.82995595\n",
      " 0.83700441 0.83700441 0.83700441 0.82863436 0.83039648 0.82995595\n",
      " 0.83436123 0.83039648 0.82995595 0.83700441 0.83700441 0.83700441\n",
      " 0.82863436 0.83039648 0.82995595 0.83436123 0.83039648 0.82995595\n",
      " 0.83700441 0.83700441 0.83700441        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.83788546 0.83744493 0.83744493 0.83876652 0.83876652 0.83876652\n",
      " 0.83920705 0.83920705 0.83920705 0.83788546 0.83744493 0.83744493\n",
      " 0.83876652 0.83876652 0.83876652 0.83920705 0.83920705 0.83920705\n",
      " 0.83788546 0.83744493 0.83744493 0.83876652 0.83876652 0.83876652\n",
      " 0.83920705 0.83920705 0.83920705 0.83832599 0.83744493 0.83744493\n",
      " 0.83876652 0.83876652 0.83876652 0.83920705 0.83920705 0.83920705\n",
      " 0.83832599 0.83744493 0.83744493 0.83876652 0.83876652 0.83876652\n",
      " 0.83920705 0.83920705 0.83920705 0.83832599 0.83744493 0.83744493\n",
      " 0.83876652 0.83876652 0.83876652 0.83920705 0.83920705 0.83920705\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.83568282 0.83436123 0.83436123\n",
      " 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758\n",
      " 0.83568282 0.83436123 0.83436123 0.83964758 0.83964758 0.83964758\n",
      " 0.83964758 0.83964758 0.83964758 0.83568282 0.83436123 0.83436123\n",
      " 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758 0.83964758\n",
      " 0.69515419 0.6969163  0.69427313 0.63700441 0.64052863 0.64317181\n",
      " 0.60792952 0.60881057 0.60881057 0.69515419 0.6969163  0.69427313\n",
      " 0.63700441 0.64052863 0.64317181 0.60792952 0.60881057 0.60881057\n",
      " 0.69515419 0.6969163  0.69427313 0.63700441 0.64052863 0.64317181\n",
      " 0.60792952 0.60881057 0.60881057        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.70440529 0.7092511  0.7061674  0.64185022 0.65022026 0.64977974\n",
      " 0.60881057 0.61409692 0.61409692 0.70440529 0.7092511  0.7061674\n",
      " 0.64185022 0.65022026 0.64977974 0.60881057 0.61409692 0.61409692\n",
      " 0.70440529 0.7092511  0.7061674  0.64185022 0.65022026 0.64977974\n",
      " 0.60881057 0.61409692 0.61409692 0.70088106 0.70704846 0.70704846\n",
      " 0.64185022 0.64889868 0.65110132 0.61189427 0.61365639 0.61365639\n",
      " 0.70088106 0.70704846 0.70704846 0.64185022 0.64889868 0.65110132\n",
      " 0.61189427 0.61365639 0.61365639 0.70088106 0.70704846 0.70704846\n",
      " 0.64185022 0.64889868 0.65110132 0.61189427 0.61365639 0.61365639\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.69162996 0.69251101 0.69339207\n",
      " 0.62863436 0.62863436 0.62863436 0.59779736 0.59427313 0.59427313\n",
      " 0.69162996 0.69251101 0.69339207 0.62863436 0.62863436 0.62863436\n",
      " 0.59779736 0.59427313 0.59427313 0.69162996 0.69251101 0.69339207\n",
      " 0.62863436 0.62863436 0.62863436 0.59779736 0.59427313 0.59427313\n",
      " 0.69339207 0.69295154 0.69251101 0.63436123 0.63348018 0.63612335\n",
      " 0.60484581 0.60792952 0.60792952 0.69339207 0.69295154 0.69251101\n",
      " 0.63436123 0.63348018 0.63612335 0.60484581 0.60792952 0.60792952\n",
      " 0.69339207 0.69295154 0.69251101 0.63436123 0.63348018 0.63612335\n",
      " 0.60484581 0.60792952 0.60792952        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.70264317 0.70704846 0.70704846 0.64096916 0.64845815 0.64889868\n",
      " 0.61057269 0.61365639 0.61365639 0.70264317 0.70704846 0.70704846\n",
      " 0.64096916 0.64845815 0.64889868 0.61057269 0.61365639 0.61365639\n",
      " 0.70264317 0.70704846 0.70704846 0.64096916 0.64845815 0.64889868\n",
      " 0.61057269 0.61365639 0.61365639 0.70088106 0.70704846 0.70704846\n",
      " 0.64185022 0.64889868 0.65110132 0.61189427 0.61365639 0.61365639\n",
      " 0.70088106 0.70704846 0.70704846 0.64185022 0.64889868 0.65110132\n",
      " 0.61189427 0.61365639 0.61365639 0.70088106 0.70704846 0.70704846\n",
      " 0.64185022 0.64889868 0.65110132 0.61189427 0.61365639 0.61365639\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.69162996 0.69339207 0.69339207\n",
      " 0.62819383 0.62863436 0.6277533  0.5969163  0.59251101 0.59251101\n",
      " 0.69162996 0.69339207 0.69339207 0.62819383 0.62863436 0.6277533\n",
      " 0.5969163  0.59251101 0.59251101 0.69162996 0.69339207 0.69339207\n",
      " 0.62819383 0.62863436 0.6277533  0.5969163  0.59251101 0.59251101\n",
      " 0.6938326  0.69603524 0.6969163  0.63656388 0.6339207  0.64008811\n",
      " 0.60528634 0.61145374 0.61145374 0.6938326  0.69603524 0.6969163\n",
      " 0.63656388 0.6339207  0.64008811 0.60528634 0.61145374 0.61145374\n",
      " 0.6938326  0.69603524 0.6969163  0.63656388 0.6339207  0.64008811\n",
      " 0.60528634 0.61145374 0.61145374        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.70132159 0.70704846 0.70704846 0.64317181 0.64801762 0.65022026\n",
      " 0.61057269 0.61365639 0.61365639 0.70132159 0.70704846 0.70704846\n",
      " 0.64317181 0.64801762 0.65022026 0.61057269 0.61365639 0.61365639\n",
      " 0.70132159 0.70704846 0.70704846 0.64317181 0.64801762 0.65022026\n",
      " 0.61057269 0.61365639 0.61365639 0.70088106 0.70704846 0.70704846\n",
      " 0.64185022 0.64889868 0.65110132 0.61189427 0.61365639 0.61365639\n",
      " 0.70088106 0.70704846 0.70704846 0.64185022 0.64889868 0.65110132\n",
      " 0.61189427 0.61365639 0.61365639 0.70088106 0.70704846 0.70704846\n",
      " 0.64185022 0.64889868 0.65110132 0.61189427 0.61365639 0.61365639\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.69162996 0.69339207 0.69339207\n",
      " 0.62819383 0.62863436 0.6277533  0.59647577 0.59251101 0.59251101\n",
      " 0.69162996 0.69339207 0.69339207 0.62819383 0.62863436 0.6277533\n",
      " 0.59647577 0.59251101 0.59251101 0.69162996 0.69339207 0.69339207\n",
      " 0.62819383 0.62863436 0.6277533  0.59647577 0.59251101 0.59251101]\n",
      "  warnings.warn(\n",
      "/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "1620 fits failed out of a total of 4860.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "810 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1227, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 1221, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 1060, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "810 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.83259912 0.83215859 0.83127753 0.83744493 0.83656388 0.83656388\n",
      " 0.83920705 0.83964758 0.83964758 0.83259912 0.83215859 0.83127753\n",
      " 0.83744493 0.83656388 0.83656388 0.83920705 0.83964758 0.83964758\n",
      " 0.83259912 0.83215859 0.83127753 0.83744493 0.83656388 0.83656388\n",
      " 0.83920705 0.83964758 0.83964758        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.84052863 0.84052863 0.84008811 0.84052863 0.84052863 0.84052863\n",
      " 0.83920705 0.83920705 0.83920705 0.84052863 0.84052863 0.84008811\n",
      " 0.84052863 0.84052863 0.84052863 0.83920705 0.83920705 0.83920705\n",
      " 0.84052863 0.84052863 0.84008811 0.84052863 0.84052863 0.84052863\n",
      " 0.83920705 0.83920705 0.83920705 0.84096916 0.84052863 0.84052863\n",
      " 0.84140969 0.84096916 0.84096916 0.83964758 0.83964758 0.83964758\n",
      " 0.84096916 0.84052863 0.84052863 0.84140969 0.84096916 0.84096916\n",
      " 0.83964758 0.83964758 0.83964758 0.84096916 0.84052863 0.84052863\n",
      " 0.84140969 0.84096916 0.84096916 0.83964758 0.83964758 0.83964758\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.84185022 0.83964758 0.84008811\n",
      " 0.84185022 0.84140969 0.84140969 0.83964758 0.83964758 0.83964758\n",
      " 0.84185022 0.83964758 0.84008811 0.84185022 0.84140969 0.84140969\n",
      " 0.83964758 0.83964758 0.83964758 0.84185022 0.83964758 0.84008811\n",
      " 0.84185022 0.84140969 0.84140969 0.83964758 0.83964758 0.83964758\n",
      " 0.82731278 0.82643172 0.82599119 0.83920705 0.83700441 0.83700441\n",
      " 0.83656388 0.83700441 0.83700441 0.82731278 0.82643172 0.82599119\n",
      " 0.83920705 0.83700441 0.83700441 0.83656388 0.83700441 0.83700441\n",
      " 0.82731278 0.82643172 0.82599119 0.83920705 0.83700441 0.83700441\n",
      " 0.83656388 0.83700441 0.83700441        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.84052863 0.84096916 0.84052863 0.84096916 0.84052863 0.84052863\n",
      " 0.83964758 0.83964758 0.83964758 0.84052863 0.84096916 0.84052863\n",
      " 0.84096916 0.84052863 0.84052863 0.83964758 0.83964758 0.83964758\n",
      " 0.84052863 0.84096916 0.84052863 0.84096916 0.84052863 0.84052863\n",
      " 0.83964758 0.83964758 0.83964758 0.84096916 0.84052863 0.84052863\n",
      " 0.84140969 0.84096916 0.84096916 0.83964758 0.83964758 0.83964758\n",
      " 0.84096916 0.84052863 0.84052863 0.84140969 0.84096916 0.84096916\n",
      " 0.83964758 0.83964758 0.83964758 0.84096916 0.84052863 0.84052863\n",
      " 0.84140969 0.84096916 0.84096916 0.83964758 0.83964758 0.83964758\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.84140969 0.83964758 0.84008811\n",
      " 0.84185022 0.84140969 0.84140969 0.83964758 0.83964758 0.83964758\n",
      " 0.84140969 0.83964758 0.84008811 0.84185022 0.84140969 0.84140969\n",
      " 0.83964758 0.83964758 0.83964758 0.84140969 0.83964758 0.84008811\n",
      " 0.84185022 0.84140969 0.84140969 0.83964758 0.83964758 0.83964758\n",
      " 0.82731278 0.82863436 0.82731278 0.84052863 0.83832599 0.83832599\n",
      " 0.83832599 0.83876652 0.83876652 0.82731278 0.82863436 0.82731278\n",
      " 0.84052863 0.83832599 0.83832599 0.83832599 0.83876652 0.83876652\n",
      " 0.82731278 0.82863436 0.82731278 0.84052863 0.83832599 0.83832599\n",
      " 0.83832599 0.83876652 0.83876652        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.84052863 0.84008811 0.84008811 0.84140969 0.84096916 0.84096916\n",
      " 0.83964758 0.83964758 0.83964758 0.84052863 0.84008811 0.84008811\n",
      " 0.84140969 0.84096916 0.84096916 0.83964758 0.83964758 0.83964758\n",
      " 0.84052863 0.84008811 0.84008811 0.84140969 0.84096916 0.84096916\n",
      " 0.83964758 0.83964758 0.83964758 0.84096916 0.84052863 0.84052863\n",
      " 0.84140969 0.84096916 0.84096916 0.83964758 0.83964758 0.83964758\n",
      " 0.84096916 0.84052863 0.84052863 0.84140969 0.84096916 0.84096916\n",
      " 0.83964758 0.83964758 0.83964758 0.84096916 0.84052863 0.84052863\n",
      " 0.84140969 0.84096916 0.84096916 0.83964758 0.83964758 0.83964758\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.84140969 0.83964758 0.84008811\n",
      " 0.84185022 0.84140969 0.84140969 0.83964758 0.83964758 0.83964758\n",
      " 0.84140969 0.83964758 0.84008811 0.84185022 0.84140969 0.84140969\n",
      " 0.83964758 0.83964758 0.83964758 0.84140969 0.83964758 0.84008811\n",
      " 0.84185022 0.84140969 0.84140969 0.83964758 0.83964758 0.83964758\n",
      " 0.69339207 0.69647577 0.69559471 0.63700441 0.63171806 0.62819383\n",
      " 0.59295154 0.58722467 0.58722467 0.69339207 0.69647577 0.69559471\n",
      " 0.63700441 0.63171806 0.62819383 0.59295154 0.58722467 0.58722467\n",
      " 0.69339207 0.69647577 0.69559471 0.63700441 0.63171806 0.62819383\n",
      " 0.59295154 0.58722467 0.58722467        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.69955947 0.70220264 0.70176211 0.64493392 0.64140969 0.64273128\n",
      " 0.60044053 0.59955947 0.59955947 0.69955947 0.70220264 0.70176211\n",
      " 0.64493392 0.64140969 0.64273128 0.60044053 0.59955947 0.59955947\n",
      " 0.69955947 0.70220264 0.70176211 0.64493392 0.64140969 0.64273128\n",
      " 0.60044053 0.59955947 0.59955947 0.70132159 0.70352423 0.70440529\n",
      " 0.64625551 0.64581498 0.64625551 0.60220264 0.60220264 0.60220264\n",
      " 0.70132159 0.70352423 0.70440529 0.64625551 0.64581498 0.64625551\n",
      " 0.60220264 0.60220264 0.60220264 0.70132159 0.70352423 0.70440529\n",
      " 0.64625551 0.64581498 0.64625551 0.60220264 0.60220264 0.60220264\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.67973568 0.68193833 0.67885463\n",
      " 0.62995595 0.62643172 0.6246696  0.5907489  0.58281938 0.58281938\n",
      " 0.67973568 0.68193833 0.67885463 0.62995595 0.62643172 0.6246696\n",
      " 0.5907489  0.58281938 0.58281938 0.67973568 0.68193833 0.67885463\n",
      " 0.62995595 0.62643172 0.6246696  0.5907489  0.58281938 0.58281938\n",
      " 0.69515419 0.69823789 0.70220264 0.64361233 0.63788546 0.63700441\n",
      " 0.60528634 0.59735683 0.59735683 0.69515419 0.69823789 0.70220264\n",
      " 0.64361233 0.63788546 0.63700441 0.60528634 0.59735683 0.59735683\n",
      " 0.69515419 0.69823789 0.70220264 0.64361233 0.63788546 0.63700441\n",
      " 0.60528634 0.59735683 0.59735683        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.70132159 0.70396476 0.70484581 0.64581498 0.64669604 0.64713656\n",
      " 0.60264317 0.60176211 0.60176211 0.70132159 0.70396476 0.70484581\n",
      " 0.64581498 0.64669604 0.64713656 0.60264317 0.60176211 0.60176211\n",
      " 0.70132159 0.70396476 0.70484581 0.64581498 0.64669604 0.64713656\n",
      " 0.60264317 0.60176211 0.60176211 0.70132159 0.70352423 0.70440529\n",
      " 0.64625551 0.64581498 0.64625551 0.60220264 0.60220264 0.60220264\n",
      " 0.70132159 0.70352423 0.70440529 0.64625551 0.64581498 0.64625551\n",
      " 0.60220264 0.60220264 0.60220264 0.70132159 0.70352423 0.70440529\n",
      " 0.64625551 0.64581498 0.64625551 0.60220264 0.60220264 0.60220264\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.68017621 0.68193833 0.6784141\n",
      " 0.63039648 0.62599119 0.62422907 0.59118943 0.58193833 0.58193833\n",
      " 0.68017621 0.68193833 0.6784141  0.63039648 0.62599119 0.62422907\n",
      " 0.59118943 0.58193833 0.58193833 0.68017621 0.68193833 0.6784141\n",
      " 0.63039648 0.62599119 0.62422907 0.59118943 0.58193833 0.58193833\n",
      " 0.69515419 0.69471366 0.69207048 0.64185022 0.63700441 0.63656388\n",
      " 0.60352423 0.59471366 0.59471366 0.69515419 0.69471366 0.69207048\n",
      " 0.64185022 0.63700441 0.63656388 0.60352423 0.59471366 0.59471366\n",
      " 0.69515419 0.69471366 0.69207048 0.64185022 0.63700441 0.63656388\n",
      " 0.60352423 0.59471366 0.59471366        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.70176211 0.70352423 0.70440529 0.64625551 0.64625551 0.64669604\n",
      " 0.60220264 0.60176211 0.60176211 0.70176211 0.70352423 0.70440529\n",
      " 0.64625551 0.64625551 0.64669604 0.60220264 0.60176211 0.60176211\n",
      " 0.70176211 0.70352423 0.70440529 0.64625551 0.64625551 0.64669604\n",
      " 0.60220264 0.60176211 0.60176211 0.70132159 0.70352423 0.70440529\n",
      " 0.64625551 0.64581498 0.64625551 0.60220264 0.60220264 0.60220264\n",
      " 0.70132159 0.70352423 0.70440529 0.64625551 0.64581498 0.64625551\n",
      " 0.60220264 0.60220264 0.60220264 0.70132159 0.70352423 0.70440529\n",
      " 0.64625551 0.64581498 0.64625551 0.60220264 0.60220264 0.60220264\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.68017621 0.68193833 0.6784141\n",
      " 0.63039648 0.62599119 0.62422907 0.59118943 0.58193833 0.58193833\n",
      " 0.68017621 0.68193833 0.6784141  0.63039648 0.62599119 0.62422907\n",
      " 0.59118943 0.58193833 0.58193833 0.68017621 0.68193833 0.6784141\n",
      " 0.63039648 0.62599119 0.62422907 0.59118943 0.58193833 0.58193833]\n",
      "  warnings.warn(\n",
      "/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "1620 fits failed out of a total of 4860.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "810 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1227, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 1221, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 1060, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "810 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/pipeline.py\", line 420, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.8287002  0.82914363 0.82914363 0.83443094 0.83399041 0.83399041\n",
      " 0.83795614 0.83795614 0.83795614 0.8287002  0.82914363 0.82914363\n",
      " 0.83443094 0.83399041 0.83399041 0.83795614 0.83795614 0.83795614\n",
      " 0.8287002  0.82914363 0.82914363 0.83443094 0.83399041 0.83399041\n",
      " 0.83795614 0.83795614 0.83795614        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.84059738 0.84059738 0.84059641 0.83883526 0.83839473 0.83839473\n",
      " 0.83971826 0.83971826 0.83971826 0.84059738 0.84059738 0.84059641\n",
      " 0.83883526 0.83839473 0.83839473 0.83971826 0.83971826 0.83971826\n",
      " 0.84059738 0.84059738 0.84059641 0.83883526 0.83839473 0.83839473\n",
      " 0.83971826 0.83971826 0.83971826 0.84280002 0.84191896 0.84191896\n",
      " 0.83927579 0.83883526 0.83883526 0.83971826 0.83971826 0.83971826\n",
      " 0.84280002 0.84191896 0.84191896 0.83927579 0.83883526 0.83883526\n",
      " 0.83971826 0.83971826 0.83971826 0.84280002 0.84191896 0.84191896\n",
      " 0.83927579 0.83883526 0.83883526 0.83971826 0.83971826 0.83971826\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.84280002 0.84235949 0.84235949\n",
      " 0.83927676 0.8388372  0.83927676 0.83971826 0.83971826 0.83971826\n",
      " 0.84280002 0.84235949 0.84235949 0.83927676 0.8388372  0.83927676\n",
      " 0.83971826 0.83971826 0.83971826 0.84280002 0.84235949 0.84235949\n",
      " 0.83927676 0.8388372  0.83927676 0.83971826 0.83971826 0.83971826\n",
      " 0.83002856 0.8295861  0.82562134 0.83310839 0.8317868  0.8317868\n",
      " 0.83399622 0.8357564  0.8357564  0.83002856 0.8295861  0.82562134\n",
      " 0.83310839 0.8317868  0.8317868  0.83399622 0.8357564  0.8357564\n",
      " 0.83002856 0.8295861  0.82562134 0.83310839 0.8317868  0.8317868\n",
      " 0.83399622 0.8357564  0.8357564         nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.84280002 0.84280002 0.84280002 0.83883526 0.83883526 0.83883526\n",
      " 0.83971826 0.83971826 0.83971826 0.84280002 0.84280002 0.84280002\n",
      " 0.83883526 0.83883526 0.83883526 0.83971826 0.83971826 0.83971826\n",
      " 0.84280002 0.84280002 0.84280002 0.83883526 0.83883526 0.83883526\n",
      " 0.83971826 0.83971826 0.83971826 0.84280002 0.84191896 0.84191896\n",
      " 0.83927579 0.83883526 0.83883526 0.83971826 0.83971826 0.83971826\n",
      " 0.84280002 0.84191896 0.84191896 0.83927579 0.83883526 0.83883526\n",
      " 0.83971826 0.83971826 0.83971826 0.84280002 0.84191896 0.84191896\n",
      " 0.83927579 0.83883526 0.83883526 0.83971826 0.83971826 0.83971826\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.84280002 0.84235949 0.84235949\n",
      " 0.83927676 0.83927676 0.83927676 0.83971826 0.83971826 0.83971826\n",
      " 0.84280002 0.84235949 0.84235949 0.83927676 0.83927676 0.83927676\n",
      " 0.83971826 0.83971826 0.83971826 0.84280002 0.84235949 0.84235949\n",
      " 0.83927676 0.83927676 0.83927676 0.83971826 0.83971826 0.83971826\n",
      " 0.82826645 0.82782398 0.82871085 0.83266786 0.83134627 0.83134627\n",
      " 0.83575543 0.83487534 0.83487534 0.82826645 0.82782398 0.82871085\n",
      " 0.83266786 0.83134627 0.83134627 0.83575543 0.83487534 0.83487534\n",
      " 0.82826645 0.82782398 0.82871085 0.83266786 0.83134627 0.83134627\n",
      " 0.83575543 0.83487534 0.83487534        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.84235949 0.8410379  0.8410379  0.83927579 0.83927579 0.83971632\n",
      " 0.83971826 0.83971826 0.83971826 0.84235949 0.8410379  0.8410379\n",
      " 0.83927579 0.83927579 0.83971632 0.83971826 0.83971826 0.83971826\n",
      " 0.84235949 0.8410379  0.8410379  0.83927579 0.83927579 0.83971632\n",
      " 0.83971826 0.83971826 0.83971826 0.84280002 0.84191896 0.84191896\n",
      " 0.83927579 0.83883526 0.83883526 0.83971826 0.83971826 0.83971826\n",
      " 0.84280002 0.84191896 0.84191896 0.83927579 0.83883526 0.83883526\n",
      " 0.83971826 0.83971826 0.83971826 0.84280002 0.84191896 0.84191896\n",
      " 0.83927579 0.83883526 0.83883526 0.83971826 0.83971826 0.83971826\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.84280002 0.84235949 0.84235949\n",
      " 0.83927676 0.83927676 0.83927676 0.83971826 0.83971826 0.83971826\n",
      " 0.84280002 0.84235949 0.84235949 0.83927676 0.83927676 0.83927676\n",
      " 0.83971826 0.83971826 0.83971826 0.84280002 0.84235949 0.84235949\n",
      " 0.83927676 0.83927676 0.83927676 0.83971826 0.83971826 0.83971826\n",
      " 0.69353246 0.68956383 0.68736215 0.67546594 0.66843201 0.66711333\n",
      " 0.59442901 0.59751852 0.59751852 0.69353246 0.68956383 0.68736215\n",
      " 0.67546594 0.66843201 0.66711333 0.59442901 0.59751852 0.59751852\n",
      " 0.69353246 0.68956383 0.68736215 0.67546594 0.66843201 0.66711333\n",
      " 0.59442901 0.59751852 0.59751852        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.69925449 0.7010166  0.69969405 0.67327008 0.67503219 0.67459263\n",
      " 0.61337174 0.60941085 0.60941085 0.69925449 0.7010166  0.69969405\n",
      " 0.67327008 0.67503219 0.67459263 0.61337174 0.60941085 0.60941085\n",
      " 0.69925449 0.7010166  0.69969405 0.67327008 0.67503219 0.67459263\n",
      " 0.61337174 0.60941085 0.60941085 0.69705475 0.69969502 0.69925255\n",
      " 0.67899695 0.67811686 0.67811783 0.61513482 0.61248971 0.61248971\n",
      " 0.69705475 0.69969502 0.69925255 0.67899695 0.67811686 0.67811783\n",
      " 0.61513482 0.61248971 0.61248971 0.69705475 0.69969502 0.69925255\n",
      " 0.67899695 0.67811686 0.67811783 0.61513482 0.61248971 0.61248971\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.68428717 0.67900373 0.67591906\n",
      " 0.66490584 0.66314954 0.66314954 0.605449   0.59752626 0.59752626\n",
      " 0.68428717 0.67900373 0.67591906 0.66490584 0.66314954 0.66314954\n",
      " 0.605449   0.59752626 0.59752626 0.68428717 0.67900373 0.67591906\n",
      " 0.66490584 0.66314954 0.66314954 0.605449   0.59752626 0.59752626\n",
      " 0.68737377 0.68736022 0.68780365 0.67635862 0.67503994 0.67371835\n",
      " 0.6050075  0.59708089 0.59708089 0.68737377 0.68736022 0.68780365\n",
      " 0.67635862 0.67503994 0.67371835 0.6050075  0.59708089 0.59708089\n",
      " 0.68737377 0.68736022 0.68780365 0.67635862 0.67503994 0.67371835\n",
      " 0.6050075  0.59708089 0.59708089        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.69793581 0.69969405 0.69969308 0.67767536 0.67899792 0.67811783\n",
      " 0.61601588 0.61072857 0.61072857 0.69793581 0.69969405 0.69969308\n",
      " 0.67767536 0.67899792 0.67811783 0.61601588 0.61072857 0.61072857\n",
      " 0.69793581 0.69969405 0.69969308 0.67767536 0.67899792 0.67811783\n",
      " 0.61601588 0.61072857 0.61072857 0.69705475 0.69969502 0.69925255\n",
      " 0.67899695 0.67811686 0.67811783 0.61513482 0.61248971 0.61248971\n",
      " 0.69705475 0.69969502 0.69925255 0.67899695 0.67811686 0.67811783\n",
      " 0.61513482 0.61248971 0.61248971 0.69705475 0.69969502 0.69925255\n",
      " 0.67899695 0.67811686 0.67811783 0.61513482 0.61248971 0.61248971\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.68428717 0.67944426 0.67547853\n",
      " 0.66534637 0.66270901 0.66314954 0.60588953 0.59840732 0.59840732\n",
      " 0.68428717 0.67944426 0.67547853 0.66534637 0.66270901 0.66314954\n",
      " 0.60588953 0.59840732 0.59840732 0.68428717 0.67944426 0.67547853\n",
      " 0.66534637 0.66270901 0.66314954 0.60588953 0.59840732 0.59840732\n",
      " 0.69441255 0.68252021 0.68560198 0.67547369 0.67195624 0.66931887\n",
      " 0.60544997 0.59796485 0.59796485 0.69441255 0.68252021 0.68560198\n",
      " 0.67547369 0.67195624 0.66931887 0.60544997 0.59796485 0.59796485\n",
      " 0.69441255 0.68252021 0.68560198 0.67547369 0.67195624 0.66931887\n",
      " 0.60544997 0.59796485 0.59796485        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.69705475 0.69969502 0.69925255 0.67899695 0.6772358  0.6776773\n",
      " 0.61557535 0.61160962 0.61160962 0.69705475 0.69969502 0.69925255\n",
      " 0.67899695 0.6772358  0.6776773  0.61557535 0.61160962 0.61160962\n",
      " 0.69705475 0.69969502 0.69925255 0.67899695 0.6772358  0.6776773\n",
      " 0.61557535 0.61160962 0.61160962 0.69705475 0.69969502 0.69925255\n",
      " 0.67899695 0.67811686 0.67811783 0.61513482 0.61248971 0.61248971\n",
      " 0.69705475 0.69969502 0.69925255 0.67899695 0.67811686 0.67811783\n",
      " 0.61513482 0.61248971 0.61248971 0.69705475 0.69969502 0.69925255\n",
      " 0.67899695 0.67811686 0.67811783 0.61513482 0.61248971 0.61248971\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.68428717 0.67944426 0.67547853\n",
      " 0.66534637 0.66270901 0.66314954 0.60544997 0.59840732 0.59840732\n",
      " 0.68428717 0.67944426 0.67547853 0.66534637 0.66270901 0.66314954\n",
      " 0.60544997 0.59840732 0.59840732 0.68428717 0.67944426 0.67547853\n",
      " 0.66534637 0.66270901 0.66314954 0.60544997 0.59840732 0.59840732]\n",
      "  warnings.warn(\n",
      "/Users/michaelromanski/anaconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    }
   ],
   "source": [
    "log_score = cross_val_score(bin_log_grid, X_train, y_train, cv=5)\n",
    "log_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(min_df = .01, max_df = .9)\n",
    "\n",
    "X_train_tf = tf.fit_transform(X_train.values)\n",
    "X_train_tf = X_train_tf.toarray()\n",
    "X_test_tf = tf.transform(X_test.values)\n",
    "X_test_tf = X_test_tf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43661971830985913"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model.fit(X_train_tf, y_train)\n",
    "\n",
    "y_pred_nb = nb_model.predict(X_test_tf)\n",
    "nb_test_acc = accuracy_score(y_test, y_pred_nb)\n",
    "nb_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fef92dd1910>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfm_nb = confusion_matrix(y_test, y_pred_nb)\n",
    "ConfusionMatrixDisplay(cfm_nb).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.91      0.34       115\n",
      "           1       0.95      0.34      0.51       595\n",
      "\n",
      "    accuracy                           0.44       710\n",
      "   macro avg       0.58      0.63      0.43       710\n",
      "weighted avg       0.83      0.44      0.48       710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pipe = Pipeline([\n",
    "    ('nb', GaussianNB())\n",
    "])\n",
    "\n",
    "nb_param_grid = {\n",
    "    'nb__var_smoothing': [1e-8, 1e-9, 1e-10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=Pipeline(steps=[(&#x27;nb&#x27;, GaussianNB())]), n_jobs=2,\n",
       "             param_grid={&#x27;nb__var_smoothing&#x27;: [1e-08, 1e-09, 1e-10]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=Pipeline(steps=[(&#x27;nb&#x27;, GaussianNB())]), n_jobs=2,\n",
       "             param_grid={&#x27;nb__var_smoothing&#x27;: [1e-08, 1e-09, 1e-10]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;nb&#x27;, GaussianNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Pipeline(steps=[('nb', GaussianNB())]), n_jobs=2,\n",
       "             param_grid={'nb__var_smoothing': [1e-08, 1e-09, 1e-10]})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_grid = GridSearchCV(nb_pipe, nb_param_grid, cv=5, n_jobs=2)\n",
    "nb_grid.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nb__var_smoothing': 1e-08}\n",
      "0.43517152296495015\n"
     ]
    }
   ],
   "source": [
    "print(nb_grid.best_params_)\n",
    "print(nb_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_binary['list_tokens'] = lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unprocessed_tweet</th>\n",
       "      <th>product</th>\n",
       "      <th>emotion</th>\n",
       "      <th>processed_tweet</th>\n",
       "      <th>emotion_encoded</th>\n",
       "      <th>list_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>wesley iphone hr tweet riseaustin dead need up...</td>\n",
       "      <td>0</td>\n",
       "      <td>[wesley, iphone, hr, tweet, riseaustin, dead, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>jessedee know fludapp awesome ipadiphone app l...</td>\n",
       "      <td>1</td>\n",
       "      <td>[jessedee, know, fludapp, awesome, ipadiphone,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>swonderlin wait ipad also sale sxsw</td>\n",
       "      <td>1</td>\n",
       "      <td>[swonderlin, wait, ipad, also, sale, sxsw]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>sxsw hope year festival crashy year iphone app...</td>\n",
       "      <td>0</td>\n",
       "      <td>[sxsw, hope, year, festival, crashy, year, iph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>sxtxstate great stuff fri sxsw marissa mayer g...</td>\n",
       "      <td>1</td>\n",
       "      <td>[sxtxstate, great, stuff, fri, sxsw, marissa, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9077</th>\n",
       "      <td>@mention your PR guy just convinced me to swit...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>mention pr guy convince switch back iphone gre...</td>\n",
       "      <td>1</td>\n",
       "      <td>[mention, pr, guy, convince, switch, back, iph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9079</th>\n",
       "      <td>&amp;quot;papyrus...sort of like the ipad&amp;quot; - ...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>quotpapyrussort like ipadquot nice lol sxsw la...</td>\n",
       "      <td>1</td>\n",
       "      <td>[quotpapyrussort, like, ipadquot, nice, lol, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9080</th>\n",
       "      <td>Diller says Google TV &amp;quot;might be run over ...</td>\n",
       "      <td>Other Google product or service</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>diller say google tv quotmight run playstation...</td>\n",
       "      <td>0</td>\n",
       "      <td>[diller, say, google, tv, quotmight, run, play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9085</th>\n",
       "      <td>I've always used Camera+ for my iPhone b/c it ...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>ive always use camera iphone bc image stabiliz...</td>\n",
       "      <td>1</td>\n",
       "      <td>[ive, always, use, camera, iphone, bc, image, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>ipad everywhere sxsw link</td>\n",
       "      <td>1</td>\n",
       "      <td>[ipad, everywhere, sxsw, link]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3548 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      unprocessed_tweet  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3     @sxsw I hope this year's festival isn't as cra...   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "...                                                 ...   \n",
       "9077  @mention your PR guy just convinced me to swit...   \n",
       "9079  &quot;papyrus...sort of like the ipad&quot; - ...   \n",
       "9080  Diller says Google TV &quot;might be run over ...   \n",
       "9085  I've always used Camera+ for my iPhone b/c it ...   \n",
       "9088                      Ipad everywhere. #SXSW {link}   \n",
       "\n",
       "                              product           emotion  \\\n",
       "0                              iPhone  Negative emotion   \n",
       "1                  iPad or iPhone App  Positive emotion   \n",
       "2                                iPad  Positive emotion   \n",
       "3                  iPad or iPhone App  Negative emotion   \n",
       "4                              Google  Positive emotion   \n",
       "...                               ...               ...   \n",
       "9077                           iPhone  Positive emotion   \n",
       "9079                             iPad  Positive emotion   \n",
       "9080  Other Google product or service  Negative emotion   \n",
       "9085               iPad or iPhone App  Positive emotion   \n",
       "9088                             iPad  Positive emotion   \n",
       "\n",
       "                                        processed_tweet  emotion_encoded  \\\n",
       "0     wesley iphone hr tweet riseaustin dead need up...                0   \n",
       "1     jessedee know fludapp awesome ipadiphone app l...                1   \n",
       "2                   swonderlin wait ipad also sale sxsw                1   \n",
       "3     sxsw hope year festival crashy year iphone app...                0   \n",
       "4     sxtxstate great stuff fri sxsw marissa mayer g...                1   \n",
       "...                                                 ...              ...   \n",
       "9077  mention pr guy convince switch back iphone gre...                1   \n",
       "9079  quotpapyrussort like ipadquot nice lol sxsw la...                1   \n",
       "9080  diller say google tv quotmight run playstation...                0   \n",
       "9085  ive always use camera iphone bc image stabiliz...                1   \n",
       "9088                          ipad everywhere sxsw link                1   \n",
       "\n",
       "                                            list_tokens  \n",
       "0     [wesley, iphone, hr, tweet, riseaustin, dead, ...  \n",
       "1     [jessedee, know, fludapp, awesome, ipadiphone,...  \n",
       "2            [swonderlin, wait, ipad, also, sale, sxsw]  \n",
       "3     [sxsw, hope, year, festival, crashy, year, iph...  \n",
       "4     [sxtxstate, great, stuff, fri, sxsw, marissa, ...  \n",
       "...                                                 ...  \n",
       "9077  [mention, pr, guy, convince, switch, back, iph...  \n",
       "9079  [quotpapyrussort, like, ipadquot, nice, lol, s...  \n",
       "9080  [diller, say, google, tv, quotmight, run, play...  \n",
       "9085  [ive, always, use, camera, iphone, bc, image, ...  \n",
       "9088                     [ipad, everywhere, sxsw, link]  \n",
       "\n",
       "[3548 rows x 6 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, figsize=(12, 6))\n",
    "\n",
    "plotted_words_and_colors = {}\n",
    "\n",
    "color_palette = sns.color_palette('pastel', n_colors = 38)\n",
    "\n",
    "data_by_emotion = [y for _, y in df_binary.groupby('emotion_encoded', as_index=False)]\n",
    "for idx, emotion_df in enumerate(data_by_emotion):\n",
    "    all_words_in_emotion = emotion_df.list_tokens.explode()\n",
    "    top_10 = all_words_in_emotion.value_counts()[:10]\n",
    "    \n",
    "    colors = []\n",
    "    for word in top_10.index:\n",
    "        if word not in plotted_words_and_colors:\n",
    "             new_color = color_palette.pop(0)\n",
    "             plotted_words_and_colors[word] = new_color\n",
    "        colors.append(plotted_words_and_colors[word])\n",
    "            \n",
    "    ax = axes[idx]\n",
    "    ax.bar(top_10.index, top_10.values, color=colors)\n",
    "    ax.set_title(emotion_df.iloc[0].emotion.title())\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sxsw       3111\n",
       "mention    2176\n",
       "link       1216\n",
       "ipad       1196\n",
       "rt          922\n",
       "apple       878\n",
       "google      692\n",
       "store       549\n",
       "iphone      522\n",
       "app         395\n",
       "Name: list_tokens, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
