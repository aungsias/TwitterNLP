{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unprocessed_tweet       0\n",
       "product              5800\n",
       "emotion                 0\n",
       "processed_tweet         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/processed_tweets.csv\", index_col=0).dropna(subset=[\"processed_tweet\", \"unprocessed_tweet\"])\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5387\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "I can't tell                           156\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8935, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_multi_dropped = df[~(df[\"emotion\"] == \"I can't tell\")].copy()\n",
    "df_multi_dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5387\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_multi_dropped[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    5387\n",
       "1    2978\n",
       "0     570\n",
       "Name: emotion_encoded, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_map = {\n",
    "    \"No emotion toward brand or product\": 2,\n",
    "    \"Positive emotion\": 1,\n",
    "    \"Negative emotion\": 0,\n",
    "}\n",
    "\n",
    "df_multi_dropped[\"emotion_encoded\"] = df_multi_dropped[\"emotion\"].map(emotion_map)\n",
    "df_multi_dropped[\"emotion_encoded\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6254,), (2681,), (6254,), (2681,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_multi_dropped[\"processed_tweet\"]\n",
    "y = df_multi_dropped[\"emotion_encoded\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for dataset in [X_train, X_test,  y_train, y_test]:\n",
    "    print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pipe_dt = Pipeline([(\"vectorizer\", TfidfVectorizer(stop_words=\"english\")), (\"dt\", DecisionTreeClassifier(random_state=42))])\n",
    "pipe_rf = Pipeline([(\"vectorizer\", TfidfVectorizer(stop_words=\"english\")), (\"rf\", RandomForestClassifier(random_state=42))])\n",
    "pipe_knn = Pipeline([(\"vectorizer\", TfidfVectorizer(stop_words=\"english\")), (\"knn\", KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "scoring_metrics = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision_weighted',\n",
    "    'f1': 'f1_weighted'\n",
    "}\n",
    "\n",
    "cv = 5\n",
    "\n",
    "def cross_val(estimator, X, y, scoring, cv):\n",
    "    cross_validation = cross_validate(estimator, X, y, cv=cv, scoring=scoring)\n",
    "    mean_cv = {score_name: np.mean(score) for score_name, score in cross_validation.items()}\n",
    "    mean_cv_df = pd.DataFrame.from_dict(mean_cv, orient='index', columns=[\"mean_cv\"])\n",
    "    mean_cv_df.drop([\"fit_time\", \"score_time\"], inplace=True)\n",
    "    return mean_cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.603517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.596029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.598384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean_cv\n",
       "test_accuracy   0.603517\n",
       "test_precision  0.596029\n",
       "test_f1         0.598384"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Decision Tree')\n",
    "cross_val(pipe_dt, X_train, y_train, scoring=scoring_metrics, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.685372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.683964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.656430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean_cv\n",
       "test_accuracy   0.685372\n",
       "test_precision  0.683964\n",
       "test_f1         0.656430"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Random Forest')\n",
    "cross_val(pipe_rf, X_train, y_train, scoring=scoring_metrics, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.634053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.615238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.610805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean_cv\n",
       "test_accuracy   0.634053\n",
       "test_precision  0.615238\n",
       "test_f1         0.610805"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('KNN')\n",
    "cross_val(pipe_knn, X_train, y_train, scoring=scoring_metrics, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dt = {\n",
    "    'dt__criterion': ['gini', 'entropy'],\n",
    "    'dt__max_depth': [10, 20, 30],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vectorizer__min_df': [0.05, 0.1, 0.15, 0.2],\n",
    "    'vectorizer__max_df': [0.9, 0.95, 1.0]\n",
    "}\n",
    "\n",
    "params_rf = {\n",
    "    'rf__n_estimators': [50, 100, 200],\n",
    "    'rf__min_samples_split': [2, 3, 4],\n",
    "    'rf__max_depth': [10, 20, 30],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vectorizer__min_df': [0.05, 0.1, 0.15, 0.2],\n",
    "    'vectorizer__max_df': [0.9, 0.95, 1.0]\n",
    "}\n",
    "\n",
    "params_knn = {\n",
    "    'knn__n_neighbors': [3, 5, 7],\n",
    "    'knn__weights': ['uniform', 'distance'],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vectorizer__min_df': [0.05, 0.1, 0.15, 0.2],\n",
    "    'vectorizer__max_df': [0.9, 0.95, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# grid_dt = GridSearchCV(pipe_dt, param_grid=params_dt, cv=cv, verbose=1, n_jobs=6, scoring=\"accuracy\")\n",
    "# grid_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 648 candidates, totalling 3240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=6)]: Done 788 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=6)]: Done 1238 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=6)]: Done 1788 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=6)]: Done 2438 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=6)]: Done 3188 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=6)]: Done 3240 out of 3240 | elapsed: 12.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vectorizer',\n",
       "                                        TfidfVectorizer(stop_words='english')),\n",
       "                                       ('rf',\n",
       "                                        RandomForestClassifier(random_state=42))]),\n",
       "             n_jobs=6,\n",
       "             param_grid={'rf__max_depth': [10, 20, 30],\n",
       "                         'rf__min_samples_split': [2, 3, 4],\n",
       "                         'rf__n_estimators': [50, 100, 200],\n",
       "                         'vectorizer__max_df': [0.9, 0.95, 1.0],\n",
       "                         'vectorizer__min_df': [0.05, 0.1, 0.15, 0.2],\n",
       "                         'vectorizer__ngram_range': [(1, 1), (1, 2)]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf = GridSearchCV(pipe_rf, param_grid=params_rf, cv=cv, verbose=1, n_jobs=6, scoring=\"accuracy\")\n",
    "grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:   28.2s\n",
      "[Parallel(n_jobs=6)]: Done 720 out of 720 | elapsed:   47.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vectorizer',\n",
       "                                        TfidfVectorizer(stop_words='english')),\n",
       "                                       ('knn', KNeighborsClassifier())]),\n",
       "             n_jobs=6,\n",
       "             param_grid={'knn__n_neighbors': [3, 5, 7],\n",
       "                         'knn__weights': ['uniform', 'distance'],\n",
       "                         'vectorizer__max_df': [0.9, 0.95, 1.0],\n",
       "                         'vectorizer__min_df': [0.05, 0.1, 0.15, 0.2],\n",
       "                         'vectorizer__ngram_range': [(1, 1), (1, 2)]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid_knn = GridSearchCV(pipe_knn, param_grid=params_knn, cv=cv, verbose=1, n_jobs=6, scoring=\"accuracy\")\n",
    "# grid_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# best_models = {\n",
    "#     \"rf\": {\"model\": grid_rf.best_estimator_, \"params\": grid_rf.best_params_},\n",
    "#     \"dt\": {\"model\": grid_dt.best_estimator_, \"params\": grid_dt.best_params_},\n",
    "#     \"knn\": {\"model\": grid_knn.best_estimator_, \"params\": grid_knn.best_params_}\n",
    "# }\n",
    "\n",
    "# with open(\"models/best_models.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(best_models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"models/best_models.pkl\", \"rb\") as f:\n",
    "    best_models = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf_best, pipe_rf_best_params = best_models[\"rf\"][\"model\"], best_models[\"rf\"][\"params\"]\n",
    "pipe_dt_best, pipe_dt_best_params = best_models[\"dt\"][\"model\"], best_models[\"dt\"][\"params\"]\n",
    "pipe_knn_best, pipe_knn_best_params = best_models[\"knn\"][\"model\"], best_models[\"knn\"][\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rf__max_depth': 10,\n",
       " 'rf__n_estimators': 200,\n",
       " 'vectorizer__max_df': 0.9,\n",
       " 'vectorizer__min_df': 0.05,\n",
       " 'vectorizer__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_rf_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dt__criterion': 'gini',\n",
       " 'dt__max_depth': 10,\n",
       " 'vectorizer__max_df': 1.0,\n",
       " 'vectorizer__min_df': 0.05,\n",
       " 'vectorizer__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_dt_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knn__n_neighbors': 7,\n",
       " 'knn__weights': 'uniform',\n",
       " 'vectorizer__max_df': 1.0,\n",
       " 'vectorizer__min_df': 0.05,\n",
       " 'vectorizer__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_knn_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       189\n",
      "           1       0.48      0.19      0.28       880\n",
      "           2       0.63      0.91      0.74      1612\n",
      "\n",
      "    accuracy                           0.61      2681\n",
      "   macro avg       0.37      0.37      0.34      2681\n",
      "weighted avg       0.54      0.61      0.54      2681\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aungs_tko91wk\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "rf_preds = grid_rf.best_estimator_.predict(X_test)\n",
    "print(classification_report(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.01      0.01       189\n",
      "           1       0.45      0.28      0.35       880\n",
      "           2       0.63      0.82      0.71      1612\n",
      "\n",
      "    accuracy                           0.59      2681\n",
      "   macro avg       0.37      0.37      0.36      2681\n",
      "weighted avg       0.53      0.59      0.54      2681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_preds = pipe_dt_best.predict(X_test)\n",
    "print(classification_report(y_test, dt_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.11      0.15       189\n",
      "           1       0.42      0.31      0.35       880\n",
      "           2       0.64      0.77      0.70      1612\n",
      "\n",
      "    accuracy                           0.57      2681\n",
      "   macro avg       0.44      0.40      0.40      2681\n",
      "weighted avg       0.54      0.57      0.55      2681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_preds = pipe_knn_best.predict(X_test)\n",
    "print(classification_report(y_test, knn_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "6254/6254 [==============================] - 6s 936us/step - loss: 0.7843 - accuracy: 0.6399\n",
      "Epoch 2/3\n",
      "6254/6254 [==============================] - 6s 909us/step - loss: 0.5852 - accuracy: 0.7523\n",
      "Epoch 3/3\n",
      "6254/6254 [==============================] - 6s 897us/step - loss: 0.4588 - accuracy: 0.8137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x206fbbec580>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_train_encoded = encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Convert to dense matrix\n",
    "X_train_vec_dense = X_train_vec.todense()\n",
    "X_test_vec_dense = X_test_vec.todense()\n",
    "\n",
    "# Model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=X_train_vec_dense.shape[1], activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))  # Assuming 3 classes\n",
    "\n",
    "# Compilation\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "model.fit(X_train_vec_dense, y_train_encoded, epochs=3, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.14      0.22       186\n",
      "           1       0.57      0.56      0.57       885\n",
      "           2       0.72      0.79      0.76      1610\n",
      "\n",
      "    accuracy                           0.67      2681\n",
      "   macro avg       0.60      0.50      0.51      2681\n",
      "weighted avg       0.66      0.67      0.66      2681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predicted_classes = np.argmax(model.predict(X_test_vec_dense), axis=1)\n",
    "print(classification_report(y_test, predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unprocessed_tweet</th>\n",
       "      <th>product</th>\n",
       "      <th>emotion</th>\n",
       "      <th>processed_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>wesley iphone hr tweet riseaustin dead need up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>jessedee know fludapp awesome ipadiphone app l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>swonderlin wait ipad also sale sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>sxsw hope year festival crashy year iphone app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>sxtxstate great stuff fri sxsw marissa mayer g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>ipad everywhere sxsw link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>wave buzz rt mention interrupt regularly sched...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9090</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>google zeiger physician never report potential...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9091</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>verizon iphone customer complain time fell bac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9092</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>rt mention google test checkin offer sxsw link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9092 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      unprocessed_tweet             product  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3     @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "...                                                 ...                 ...   \n",
       "9088                      Ipad everywhere. #SXSW {link}                iPad   \n",
       "9089  Wave, buzz... RT @mention We interrupt your re...                 NaN   \n",
       "9090  Google's Zeiger, a physician never reported po...                 NaN   \n",
       "9091  Some Verizon iPhone customers complained their...                 NaN   \n",
       "9092  Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...                 NaN   \n",
       "\n",
       "                                 emotion  \\\n",
       "0                       Negative emotion   \n",
       "1                       Positive emotion   \n",
       "2                       Positive emotion   \n",
       "3                       Negative emotion   \n",
       "4                       Positive emotion   \n",
       "...                                  ...   \n",
       "9088                    Positive emotion   \n",
       "9089  No emotion toward brand or product   \n",
       "9090  No emotion toward brand or product   \n",
       "9091  No emotion toward brand or product   \n",
       "9092  No emotion toward brand or product   \n",
       "\n",
       "                                        processed_tweet  \n",
       "0     wesley iphone hr tweet riseaustin dead need up...  \n",
       "1     jessedee know fludapp awesome ipadiphone app l...  \n",
       "2                   swonderlin wait ipad also sale sxsw  \n",
       "3     sxsw hope year festival crashy year iphone app...  \n",
       "4     sxtxstate great stuff fri sxsw marissa mayer g...  \n",
       "...                                                 ...  \n",
       "9088                          ipad everywhere sxsw link  \n",
       "9089  wave buzz rt mention interrupt regularly sched...  \n",
       "9090  google zeiger physician never report potential...  \n",
       "9091  verizon iphone customer complain time fell bac...  \n",
       "9092     rt mention google test checkin offer sxsw link  \n",
       "\n",
       "[9092 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['unprocessed_tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
